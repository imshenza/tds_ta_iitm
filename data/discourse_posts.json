[
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/cors-settings-for-the-deployed-project/179183/2",
    "posts": [
      {
        "user_id": null,
        "content": "I have allowed\nhttps://exam.sanand.workers.dev\nin CORS of TDS project 1. Is this enough or should I give access to every site i.e [“*”] ?"
      },
      {
        "user_id": null,
        "content": "@carlton\nsir, please clarify"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/getting-an-api-key-error-upon-running-npx-y-promptfoo-eval-config-project-tds-virtual-ta-promptfoo-yaml/178878/3",
    "posts": [
      {
        "user_id": null,
        "content": "[FAIL] API error: 401  Unauthorized  {“error”:{“message”:\"Inc… API key provided: sk-proj-*************** You can find your API key at\nhttps://platform.openai\n.…"
      },
      {
        "user_id": null,
        "content": "@HritikRoshan_HRM\nsir\n@carlton\nsir could you pls help"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/project-1-of-tools-in-data-science/179210/3",
    "posts": [
      {
        "user_id": null,
        "content": "What will be the output of curl statement?"
      },
      {
        "user_id": null,
        "content": "@archie123\nTopic moved to the appropriate category in order to get faster responses.\nPlease make it easier for others to help you, by ensuring that topics are created in the correct categories."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/a-humble-request-to-the-tds-course-team/179034/1",
    "posts": [
      {
        "user_id": null,
        "content": "@carlton\nand\n@Jivraj\nRespected Sir\nIt was my first time doing web scraping and other tasks required for this project. After watching the live sessions, I realized that my approach was wrong. The live sessions are really good\nbut\n, they are being conducted too close to the deadline (started on 10th June). In the sessions, it was said that this project could be completed in a day, but I don’t feel that this is the case for me (not even close), though that might just be my own inefficiency.\nAside from that, the method of using the Gemini model demonstrated in the sessions only allowed me to generate embeddings for the first 100 chunks (max per day), there are way more than that in my workflow. I have to spend time finding other alternatives to create embeddings before I make the final submission with the openAI api. So, I humbly request, if it is possible, please consider extending the deadline by a few days. There is not enough time to absorb what was taught in the live sessions and implement it as complete beginner.\nThank you."
      },
      {
        "user_id": null,
        "content": "23f1000917:\nAside from that, the method of using the Gemini model demonstrated in the sessions only allowed me to generate embeddings for the first 100 chunks (max per day), there are way more than that in my workflow. I have to spend time finding other alternatives to create embeddings before I make the final submission with the openAI api. So, I humbly request, if it is possible, please consider extending the deadline by a few days. There is not enough time to absorb what was taught in the live sessions and implement it as complete beginner.\nit will be helpful if deadline extended by 2-3 days"
      },
      {
        "user_id": null,
        "content": "Yes sir please extend the deadline"
      },
      {
        "user_id": null,
        "content": "please extend the deadline"
      },
      {
        "user_id": null,
        "content": "please extend the deadline"
      },
      {
        "user_id": null,
        "content": "Already extended till 18th.\nOn another topic\nPlease post any questions related to\nProject 1\nPlease use markdown code formatting (fenced code blocks beginning with ```) when sharing code (rather than screenshots). It’s easier for us to copy-paste and test.\nDeadline:\nJune 14, 2025 11:59 PM\nDeadline:\nTomorrow 11:59 PM"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/output-from-the-curl-command-of-individual-question-is-different-from-the-promptfoo-evaluation/179200",
    "posts": [
      {
        "user_id": null,
        "content": "For the question\nI know Docker but have not used Podman before. Should I use Docker for this course?\nThe output I have got using this command in terminal was\ncurl \"http://localhost:8000/api/\"   -H \"Content-Type: application/json\"   -d \"{\\\"question\\\": \\\"I know Docker but have not used Podman before. Should I use Docker for this course?\\\"}\"\n*Output : *\n{\n\"answer\"\n:\n\"Yes, you can definitely use Docker for this course. While Podman is recommended because it offers better security and has a slightly more open license, Docker works in the same way and is widely used. If you're already familiar with Docker, you can continue using it without any issues. Just make sure to follow the same steps for building, running, and pushing images as you would with Podman.\"\n,\n\"links\"\n:\n[\n{\n\"url\"\n:\n\"https://tds.s-anand.net/#/docker\"\n,\n\"text\"\n:\n\"Podman is compatible with Docker and has better security (and a slightly more open license). In this course, we recommend Podman but Docker works in the same way.\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/project-1-llm-based-automation-agent-discussion-thread-tds-jan-2025/164277/312\"\n,\n\"text\"\n:\n\"@s.anand Sir please tell me this I am not using podman i am using docker for building and hosting is it fine sir ?\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/ga2-deployment-tools-discussion-thread-tds-jan-2025/161120/19\"\n,\n\"text\"\n:\n\"@Nelson I would recommend Podman or Docker CE rather than Docker Desktop. Docker Desktop is not free for organizations over 250 people and many organizations have therefore moved away from it.\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/ga1-development-tools-discussion-thread-tds-jan-2025/161083/17\"\n,\n\"text\"\n:\n\"Hi Suhani,\\nnpm does not require docker. Kind regards\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/tds-official-project1-discrepencies/171141/138\"\n,\n\"text\"\n:\n\"on a side note, to validate and test our docker/podman images on a platform outside of our dev environment we can use https://labs.play-with-docker.com/.. this is a free platform to download run and test docker images …\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/ga2-deployment-tools-discussion-thread-tds-jan-2025/161120/22\"\n,\n\"text\"\n:\n\"Thank you, Sir! What is the Docker image source? It should look like: https://hub.docker.com/repository/docker/$USER/$REPO/general\\n\\nIf I use Podman, will the answer be correct assuming I have done all steps correctly?\"\n}\n,\n{\n\"url\"\n:\n\"https://tds.s-anand.net/#/docker\"\n,\n\"text\"\n:\n\"To build, run, and deploy the container, run these commands:\\n# Create an account on https://hub.docker.com/ and then login\\npodman\\nlogin docker.io\\n# Build and run the container\\npodman\\nbuild\\n-t\\npy-hello\\n. podman\\nrun\\n-it\\npy-hello\\n# Push the container to Docker Hub. Replace $DOCKER_HUB_USERNAME with your Docker Hub username.\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/project-1-llm-based-automation-agent-discussion-thread-tds-jan-2025/164277/221\"\n,\n\"text\"\n:\n\"But when I use podman i keep getting errror.\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/project-1-llm-based-automation-agent-discussion-thread-tds-jan-2025/164277/27\"\n,\n\"text\"\n:\n\"23f1002382:\\n\\nRegarding Wednenday 9-10 pm live session, maybe the instructors could also discuss how to use docker as a virtual environmen\\n\\n\\nIn Tuesday’s(21 January) session we had discussed docker towards ending of session. What was discussed in that live session regarding docker:\\n\\nSearch for existing containers on repositories such as dockerhub. Pull an existing docker image.\"\n}\n,\n{\n\"url\"\n:\n\"https://tds.s-anand.net/#/docker\"\n,\n\"text\"\n:\n\"Containers: Docker, Podman\\nTools in Data Science\\nTools in Data Science\\n1. Development Tools\\nEditor: VS Code\\nAI Code Editors: GitHub Copilot\\nPython tools: uv\\nJavaScript tools: npx\\nUnicode\\nBrowser: DevTools\\nCSS Selectors\\nJSON\\nTerminal: Bash\\nAI Terminal Tools: llm\\nSpreadsheet: Excel, Google Sheets\\nDatabase: SQLite\\nVersion Control: Git, GitHub\\n2. Deployment Tools\\nMarkdown\\nImages: Compression\\nStatic hosting: GitHub Pages\\nNotebooks: Google Colab\\nServerless hosting: Vercel\\nCI/CD: GitHub Actions\\nContainers: Docker, Podman\\nContainers: Docker, Podman\\nDevContainers: GitHub Codespaces\\nTunneling: ngrok\\nCORS\\nREST APIs\\nWeb Framework: FastAPI\\nAuthentication: Google Auth\\nLocal LLMs: Ollama\\n3.\"\n}\n]\n}\nNOTE : With the RAG out put I’ve selected the top 10 outputs.\nWith the evalution from the promptfoo for the same question\nI know Docker but have not used Podman before. Should I use Docker for this course?\nther response was different.\n{\n\"answer\"\n:\n\"Hello! \\n\\nFor this course, you can use either Docker or Podman, as both are capable containerization tools. However, based on the context provided, it seems that Docker Desktop might not be the preferred choice, especially for organizations or environments where licensing costs are a concern.\\n\\nIf you're already familiar with Docker, you can continue using it. If you're interested in exploring an alternative, Podman is a good option—it is compatible with many Docker commands and offers similar functionality without requiring a daemon or root privileges.\\n\\nIn summary:\\n- If you're comfortable with Docker, you can proceed with it.\\n- If you'd like to try Podman, it's a suitable alternative and worth exploring.\\n\\nLet me know if you need guidance on setting up or using Podman!\"\n,\n\"links\"\n:\n[\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/161120/19\"\n,\n\"text\"\n:\n\"@Nelson I would recommend Podman or Docker CE rather than Docker Desktop.\\nDocker Desktop is not free for organizations over 250 people and many organizations have therefore moved away from it.\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/161083/17\"\n,\n\"text\"\n:\n\"Hi Suhani,\\nnpm does not require docker.\\nKind regards\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/167415/2\"\n,\n\"text\"\n:\n\"The name of the Dockerfile should be “Dockerfile” indeed, more over check other sections of your submission like\\n\\nIs the GitHub repo public?\\nDoes it have an MIT license?\\nDoes it have a DockerFile?\\nIs the Docker image accessible?\\n\"\n}\n]\n}\nI have tried clearing the local cache using bleachbit I would clear all cache but nothing worked. Also\nhttps://tds.s-anand.net/#/docker\nis also present in the output from\nCurl command in the terminal\n. but not in the output from the promptfoo evauation                                                                                                                                                                  Help Please!!!"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/help-required-in-project-1-scrapping-discourse-data/179153",
    "posts": [
      {
        "user_id": null,
        "content": "Hello,\nI’m new to coding and still learning. I’m trying to scrape data from a Discourse forum and have identified the relevant API endpoint. However, I’m having trouble with authentication—I keep receiving a 403 error stating that the user is not logged in or doesn’t have permission to perform the action.\nI’ve tried using the most recent cookies from my browser, but I still get the same error. Can someone help me figure out what I’m doing wrong?"
      },
      {
        "user_id": null,
        "content": "Honestly, you must be unintentionally making some sort of a mistake. I will give you a function definition that should work.\nimport\nrequests\ndef\ncreate_session\n():\n\n    domain =\n\"discourse.onlinedegree.iitm.ac.in\"\nsession = requests.Session()\n\n    cookies =\ndict\n(\n\n        _t =\n\"_______________\"\n,\n\n        _forum_session =\n\"_______________\"\n)\nfor\nname, value\nin\ncookies.items():\n\n        session.cookies.\nset\n(name, value, domain=domain)\nreturn\nsession\nUse this\nsession\nobject using\nsession.get(url, headers=headers)\n.\nYou must create a session to mimic a real browser. Good luck!"
      },
      {
        "user_id": null,
        "content": "did u get an api key for discourse to scrape the data can u help me with that\n@23f1000917"
      },
      {
        "user_id": null,
        "content": "i am currently running it in local host 8000 other functionalities are working this is the problem data scraping"
      },
      {
        "user_id": null,
        "content": "Okay, I will explain it to you.\nUpon visiting discourse and signing in with your account, you get ‘cookies’ containing information that can be used to authorize you. These cookies are sent with each subsequent\nrequest\nyou make to discourse, if the website does not recognize these\ncookies\n, they simply reject your request with a status code of 403.\nIf you want to scrape the posts, you need to get these\ncookies\n. So, where are these cookies stored? Well, just sign into discourse with your IITM account (in Chrome). Then, visit the following URL:\nhttps://discourse.onlinedegree.iitm.ac.in/session/current.json\nOnce the page has opened and you can see JSON data, do the following:\nright click > inspect > application > cookies > https://discourse.onlinedegree.iitm.ac.in/\n.\nNow, you will see a bunch of cookies, which are similar to a python dictionary containing key-value pairs. You only care about two such keys, one is\n_t\nand the other one is\n_forum_session\n.\nSave the value of these cookie keys in a python file like\nmy_cookies.py\n:\n# my_cookies.py\n_t =\n\"your _t cookie\"\n_forum_session =\n\"your _forum_session cookie\"\nNow, these can be imported into other files using:\nfrom\nmy_cookies\nimport\n_t, _forum_session\n\nauth_cookie:\ndict\n= {\n'_t'\n: _t ,\n'_forum_session'\n: _forum_session }\nNote that these\ncookies keep changing\n, when you make new requests you get different values that replace the current values of your\nsession\n. You can think of the session as a user.\nNow, look at my previous reply:\nhttps://discourse.onlinedegree.iitm.ac.in/t/help-required-in-project-1-scrapping-discourse-data/179153/2?u=23f1000917\nThe\nrequests\nmodule is used to send requests to websites in python.  You need to install it using\npip install requests\n. You create a session object and add your cookies in it. This automatically handles the\nchanging and replacement of cookie values\nwhen you make requests.\nSearch for a tutorial on the\nrequests\nmodule to understand how to make requests using it. Just know that you can do the something like this:\nimport\nrequests \n\nURL =\n\"https://example.com/latest_threads.json\"\nsession = requests.Session()\nresponse = session.get(URL)\nif\nresponse.status_code=\n200\n:\n    data = response.json()\n# get json data\nLastly, watch the live sessions conducted by IITM on 10th June and next few days. You can find them in your google calendar."
      },
      {
        "user_id": null,
        "content": "@23f1000917\nthanks bro will try this out"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/drop-course-window/179104/1",
    "posts": [
      {
        "user_id": null,
        "content": "@carlton\nsir I’m unable to continue with the course, is it possible to drop course somehow, the option is not visible anywhere. Please guide.\nRegards\nNitin Dixit\n23f2005404"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/guide-for-tds-project-1/178649/1",
    "posts": [
      {
        "user_id": null,
        "content": "Where can I get a reference or some material that may Guide me to complete the project."
      },
      {
        "user_id": null,
        "content": "github.com\nGitHub - 23f3004008/TDS-Project1-Data\nContribute to 23f3004008/TDS-Project1-Data development by creating an account on GitHub.\nThis is a good starting point for web scraping"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/having-issue-while-submitting-the-project/179139/1",
    "posts": [
      {
        "user_id": null,
        "content": "Hello, i decided to deploy my virtual assistant project for TDS May 2025 term on Render.\nthe url is accepting GET requests for “/” endpoint and POST requests for “/api/” endpoint as instructed by Sirs. but it seems that the form where i’m supposed to provide github repo link and deployment public url, is sending an OPTIONS request to my Render deployed application, which it is dismissing by saying method not allowed. what to do??\nEDIT: enabling CORS let me send an OPTIONS request from the submission form so i was able to submit.\nlater i sent promptfoo as well as regular curls to Render url and they worked too. Although once it shut down, it just isn’t starting back up again; sending curls now gives me some really long html and doesn’t even send any api calls to the render url. what to do?\n@carlton\n@Jivraj"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-may-2025/178881/1",
    "posts": [
      {
        "user_id": null,
        "content": "Please post any questions related to\nGraded Assignment 4 - Data Sourcing\n.\nDeadline:\nSunday, June 22, 2025 11:59 PM\n@carlton\n@Jivraj\n@HritikRoshan_HRM"
      },
      {
        "user_id": null,
        "content": "Subject:\nIssue with Scraping BBC Weather API for Nur-Sultan JSON Forecast\nQuestion 4: Scraping BBC Weather API for Nur-Sultan Weather Forecast\nI’m trying to retrieve the JSON weather forecast description for Nur-Sultan using the BBC Weather API. However, I noticed that the BBC website lists the city as “Astana” instead of Nur-Sultan. When I attempt to use the JSON data for Astana, I encounter the following error:\nTypeError: Cannot read properties of undefined (reading ‘id’)\nHow should I proceed to correctly scrape the weather forecast for Nur-Sultan?  how can I resolve the TypeError issue? Any guidance on handling city name"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/promptfoo-yaml-not-fetching-results/179348",
    "posts": [
      {
        "user_id": null,
        "content": "whenever i use curl to ask questions it fetches results fine however the same questions when asked by promptfoo wont get any results and “say i could not find”\nScreenshot 2025-06-16 at 8.46.52 PM\n1016×540 54.3 KB"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/help-required-in-project-1-scrapping-discourse-data/179153/1",
    "posts": [
      {
        "user_id": null,
        "content": "Hello,\nI’m new to coding and still learning. I’m trying to scrape data from a Discourse forum and have identified the relevant API endpoint. However, I’m having trouble with authentication—I keep receiving a 403 error stating that the user is not logged in or doesn’t have permission to perform the action.\nI’ve tried using the most recent cookies from my browser, but I still get the same error. Can someone help me figure out what I’m doing wrong?"
      },
      {
        "user_id": null,
        "content": "Honestly, you must be unintentionally making some sort of a mistake. I will give you a function definition that should work.\nimport\nrequests\ndef\ncreate_session\n():\n\n    domain =\n\"discourse.onlinedegree.iitm.ac.in\"\nsession = requests.Session()\n\n    cookies =\ndict\n(\n\n        _t =\n\"_______________\"\n,\n\n        _forum_session =\n\"_______________\"\n)\nfor\nname, value\nin\ncookies.items():\n\n        session.cookies.\nset\n(name, value, domain=domain)\nreturn\nsession\nUse this\nsession\nobject using\nsession.get(url, headers=headers)\n.\nYou must create a session to mimic a real browser. Good luck!"
      },
      {
        "user_id": null,
        "content": "did u get an api key for discourse to scrape the data can u help me with that\n@23f1000917"
      },
      {
        "user_id": null,
        "content": "i am currently running it in local host 8000 other functionalities are working this is the problem data scraping"
      },
      {
        "user_id": null,
        "content": "Okay, I will explain it to you.\nUpon visiting discourse and signing in with your account, you get ‘cookies’ containing information that can be used to authorize you. These cookies are sent with each subsequent\nrequest\nyou make to discourse, if the website does not recognize these\ncookies\n, they simply reject your request with a status code of 403.\nIf you want to scrape the posts, you need to get these\ncookies\n. So, where are these cookies stored? Well, just sign into discourse with your IITM account (in Chrome). Then, visit the following URL:\nhttps://discourse.onlinedegree.iitm.ac.in/session/current.json\nOnce the page has opened and you can see JSON data, do the following:\nright click > inspect > application > cookies > https://discourse.onlinedegree.iitm.ac.in/\n.\nNow, you will see a bunch of cookies, which are similar to a python dictionary containing key-value pairs. You only care about two such keys, one is\n_t\nand the other one is\n_forum_session\n.\nSave the value of these cookie keys in a python file like\nmy_cookies.py\n:\n# my_cookies.py\n_t =\n\"your _t cookie\"\n_forum_session =\n\"your _forum_session cookie\"\nNow, these can be imported into other files using:\nfrom\nmy_cookies\nimport\n_t, _forum_session\n\nauth_cookie:\ndict\n= {\n'_t'\n: _t ,\n'_forum_session'\n: _forum_session }\nNote that these\ncookies keep changing\n, when you make new requests you get different values that replace the current values of your\nsession\n. You can think of the session as a user.\nNow, look at my previous reply:\nhttps://discourse.onlinedegree.iitm.ac.in/t/help-required-in-project-1-scrapping-discourse-data/179153/2?u=23f1000917\nThe\nrequests\nmodule is used to send requests to websites in python.  You need to install it using\npip install requests\n. You create a session object and add your cookies in it. This automatically handles the\nchanging and replacement of cookie values\nwhen you make requests.\nSearch for a tutorial on the\nrequests\nmodule to understand how to make requests using it. Just know that you can do the something like this:\nimport\nrequests \n\nURL =\n\"https://example.com/latest_threads.json\"\nsession = requests.Session()\nresponse = session.get(URL)\nif\nresponse.status_code=\n200\n:\n    data = response.json()\n# get json data\nLastly, watch the live sessions conducted by IITM on 10th June and next few days. You can find them in your google calendar."
      },
      {
        "user_id": null,
        "content": "@23f1000917\nthanks bro will try this out"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/output-from-the-curl-command-of-individual-question-is-different-from-the-promptfoo-evaluation/179200/1",
    "posts": [
      {
        "user_id": null,
        "content": "For the question\nI know Docker but have not used Podman before. Should I use Docker for this course?\nThe output I have got using this command in terminal was\ncurl \"http://localhost:8000/api/\"   -H \"Content-Type: application/json\"   -d \"{\\\"question\\\": \\\"I know Docker but have not used Podman before. Should I use Docker for this course?\\\"}\"\n*Output : *\n{\n\"answer\"\n:\n\"Yes, you can definitely use Docker for this course. While Podman is recommended because it offers better security and has a slightly more open license, Docker works in the same way and is widely used. If you're already familiar with Docker, you can continue using it without any issues. Just make sure to follow the same steps for building, running, and pushing images as you would with Podman.\"\n,\n\"links\"\n:\n[\n{\n\"url\"\n:\n\"https://tds.s-anand.net/#/docker\"\n,\n\"text\"\n:\n\"Podman is compatible with Docker and has better security (and a slightly more open license). In this course, we recommend Podman but Docker works in the same way.\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/project-1-llm-based-automation-agent-discussion-thread-tds-jan-2025/164277/312\"\n,\n\"text\"\n:\n\"@s.anand Sir please tell me this I am not using podman i am using docker for building and hosting is it fine sir ?\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/ga2-deployment-tools-discussion-thread-tds-jan-2025/161120/19\"\n,\n\"text\"\n:\n\"@Nelson I would recommend Podman or Docker CE rather than Docker Desktop. Docker Desktop is not free for organizations over 250 people and many organizations have therefore moved away from it.\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/ga1-development-tools-discussion-thread-tds-jan-2025/161083/17\"\n,\n\"text\"\n:\n\"Hi Suhani,\\nnpm does not require docker. Kind regards\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/tds-official-project1-discrepencies/171141/138\"\n,\n\"text\"\n:\n\"on a side note, to validate and test our docker/podman images on a platform outside of our dev environment we can use https://labs.play-with-docker.com/.. this is a free platform to download run and test docker images …\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/ga2-deployment-tools-discussion-thread-tds-jan-2025/161120/22\"\n,\n\"text\"\n:\n\"Thank you, Sir! What is the Docker image source? It should look like: https://hub.docker.com/repository/docker/$USER/$REPO/general\\n\\nIf I use Podman, will the answer be correct assuming I have done all steps correctly?\"\n}\n,\n{\n\"url\"\n:\n\"https://tds.s-anand.net/#/docker\"\n,\n\"text\"\n:\n\"To build, run, and deploy the container, run these commands:\\n# Create an account on https://hub.docker.com/ and then login\\npodman\\nlogin docker.io\\n# Build and run the container\\npodman\\nbuild\\n-t\\npy-hello\\n. podman\\nrun\\n-it\\npy-hello\\n# Push the container to Docker Hub. Replace $DOCKER_HUB_USERNAME with your Docker Hub username.\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/project-1-llm-based-automation-agent-discussion-thread-tds-jan-2025/164277/221\"\n,\n\"text\"\n:\n\"But when I use podman i keep getting errror.\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/project-1-llm-based-automation-agent-discussion-thread-tds-jan-2025/164277/27\"\n,\n\"text\"\n:\n\"23f1002382:\\n\\nRegarding Wednenday 9-10 pm live session, maybe the instructors could also discuss how to use docker as a virtual environmen\\n\\n\\nIn Tuesday’s(21 January) session we had discussed docker towards ending of session. What was discussed in that live session regarding docker:\\n\\nSearch for existing containers on repositories such as dockerhub. Pull an existing docker image.\"\n}\n,\n{\n\"url\"\n:\n\"https://tds.s-anand.net/#/docker\"\n,\n\"text\"\n:\n\"Containers: Docker, Podman\\nTools in Data Science\\nTools in Data Science\\n1. Development Tools\\nEditor: VS Code\\nAI Code Editors: GitHub Copilot\\nPython tools: uv\\nJavaScript tools: npx\\nUnicode\\nBrowser: DevTools\\nCSS Selectors\\nJSON\\nTerminal: Bash\\nAI Terminal Tools: llm\\nSpreadsheet: Excel, Google Sheets\\nDatabase: SQLite\\nVersion Control: Git, GitHub\\n2. Deployment Tools\\nMarkdown\\nImages: Compression\\nStatic hosting: GitHub Pages\\nNotebooks: Google Colab\\nServerless hosting: Vercel\\nCI/CD: GitHub Actions\\nContainers: Docker, Podman\\nContainers: Docker, Podman\\nDevContainers: GitHub Codespaces\\nTunneling: ngrok\\nCORS\\nREST APIs\\nWeb Framework: FastAPI\\nAuthentication: Google Auth\\nLocal LLMs: Ollama\\n3.\"\n}\n]\n}\nNOTE : With the RAG out put I’ve selected the top 10 outputs.\nWith the evalution from the promptfoo for the same question\nI know Docker but have not used Podman before. Should I use Docker for this course?\nther response was different.\n{\n\"answer\"\n:\n\"Hello! \\n\\nFor this course, you can use either Docker or Podman, as both are capable containerization tools. However, based on the context provided, it seems that Docker Desktop might not be the preferred choice, especially for organizations or environments where licensing costs are a concern.\\n\\nIf you're already familiar with Docker, you can continue using it. If you're interested in exploring an alternative, Podman is a good option—it is compatible with many Docker commands and offers similar functionality without requiring a daemon or root privileges.\\n\\nIn summary:\\n- If you're comfortable with Docker, you can proceed with it.\\n- If you'd like to try Podman, it's a suitable alternative and worth exploring.\\n\\nLet me know if you need guidance on setting up or using Podman!\"\n,\n\"links\"\n:\n[\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/161120/19\"\n,\n\"text\"\n:\n\"@Nelson I would recommend Podman or Docker CE rather than Docker Desktop.\\nDocker Desktop is not free for organizations over 250 people and many organizations have therefore moved away from it.\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/161083/17\"\n,\n\"text\"\n:\n\"Hi Suhani,\\nnpm does not require docker.\\nKind regards\"\n}\n,\n{\n\"url\"\n:\n\"https://discourse.onlinedegree.iitm.ac.in/t/167415/2\"\n,\n\"text\"\n:\n\"The name of the Dockerfile should be “Dockerfile” indeed, more over check other sections of your submission like\\n\\nIs the GitHub repo public?\\nDoes it have an MIT license?\\nDoes it have a DockerFile?\\nIs the Docker image accessible?\\n\"\n}\n]\n}\nI have tried clearing the local cache using bleachbit I would clear all cache but nothing worked. Also\nhttps://tds.s-anand.net/#/docker\nis also present in the output from\nCurl command in the terminal\n. but not in the output from the promptfoo evauation                                                                                                                                                                  Help Please!!!"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/about-the-tools-in-data-science-category/23335/1",
    "posts": [
      {
        "user_id": null,
        "content": "This category is created to address\nsubject-specific queries\nrelated to\nTools in Data Science\n- Why should people use this category? What is it for?\nThe larger goal of the Discourse forum is to act as a Knowledge base for the course. You can make this more productive by\nElaborating your question sufficiently and supporting it with steps that you have already tried at your end before posting this question\nSharing additional content or explanations related to the topic being discussed\n-  Are there any rules for posting in this category?\nBefore you create a new post,\nreview the existing threads\nto see if there are already highly similar or identical postings. Discourse will suggest similar posts once you start typing titles\nTag the post appropriately\nso that it gets indexed correctly in our Knowledge Base. For instance, if your query is on an Activity Question in Week 1 then use the tags\n#\nactivity-question\n,\n#\nweek-1\nProvide a meaningful title to your post\nthat contains the topic/details of your query so that it can be searched by others easily. For instance: Do not use the titles like\n“AQ1.1 Q3”\nwhich just gives question number alone.  Instead use a more meaningful title like -\n“Need help in calculating the\nN\nt\nh\nN^{th}\nN\nt\nh\nprime number”\nType in your question and explanations\nrather than pasting images or screenshots.\n- What is NOT Permitted in this category?\nBeing argumentative or sarcastic\nUse of abusive/strong language\nPosting support/logistics related query\nUnnecessarily tagging Faculty/Instructors in posts\nPosting Solutions or discussing solutions to graded assignments\n- Who will be moderating the content in this forum?\nThe foum will be moderated by Course Instructors. They will have the authority to decide whether a post violates forum rules/guidelines. You can flag/report any such violations that you observe by clicking on\nicon on the post. Please do mention the reason why you are flagging the topic.\n- What are the disciplinary actions if some one violates the rules and guidelines of the forum?\nThe flagged posts that violates forum rules/guidelines will be hidden. Repeated violation of the rules can result in the offender being removal from the forum."
      },
      {
        "user_id": null,
        "content": "Can some course instructor talk more about the Discover the problem statement ?"
      },
      {
        "user_id": null,
        "content": "From the graded assignment we can’t understand what is right way to think unless we make trial and error. can we have some practice assignment to understand our thinking process is properly aligned or not. With just GA it would be difficult to assess."
      },
      {
        "user_id": null,
        "content": "Apart from what\n@CKPIITM\nobserved about this course, here’s my first impression of this course…Granted, it has been only a week, but I think I must go ahead anyway…\nThe week-1 clearly shows a lack of planning, from the program as well as the specific course perspective.  It starts off with an example that completely caught me off-guard.  The first video discussed an example that left me wondering why is the instructor even discussing all of that, at this point.  What’s the context and the motivation?  Moreover, every slide is filled to the brim with text.  Can’t decide whether to read it or listen to the speaker.  Neither does give me much understanding anyway.  It was filled with terminology that I’m yet to pick up.  The speaker didn’t apparently know much about who the audience is, and what are they aware of, and what they aren’t…In short, it failed to implement any of the very matter it speaks of - Understanding the problem.\nSummary.  I feel the course is offered too early.  Rather, I took it a little too early.\nDefinitely, I can’t relate to most things the speaker is talking about.  At least, I don’t see how and where the ideas will gel with our program.  I’m sure it does, but now, I don’t know how.\nSorry, I’d never been as critical about anything as this one.  I just had to.  I’m willing to hear different opinions.\nI’m awaiting the announcement from IIT for the course drop."
      },
      {
        "user_id": null,
        "content": "I am totally clue less about the expectation of instructor from the participants of this course. And the question of graded assignment was something, I found myself out of context. I know I can pass any course but I don’t just wanna pass without any concrete learning. The real problem this time is not TIME.\nHopefully courses instructor will guide us through this conundrum."
      },
      {
        "user_id": null,
        "content": "I feel like we need an introduction video of some kind for this. Or it should have been suggested only to those who have completed all the ML courses. From the offset, there are people who don’t know what modelling is, the different kinds of models etc. but there is no explanation for all this. Granted, it was mentioned in the orientation that it would only be tools with no explanation.\nBut I am hopeful that this will get better in the later weeks as this is the only “comprehension” type of week (reminiscent of the english courses lol). The other weeks will all involve practical approach and coding. As long as adequate time is spent on introducing each new thing, I think it should be okay."
      },
      {
        "user_id": null,
        "content": "As of now, I’m set on my mind to drop the course, unless something hopeful turns up next week.  Will continue after all other ML courses are done…"
      },
      {
        "user_id": null,
        "content": "Some sort of introduction would have been better instead of just diving into the topic. Nevertheless, I hope we get practice questions/assignment to comprehend the concepts.\nIn the meantime if anyone gets some sort of resources to practice elsewhere, do share."
      },
      {
        "user_id": null,
        "content": "Adding to the discussion here, I’d also have to say it’s quite the same feeling for me. I got lost while going through the videos. At first, I thought it’s some issue with me, because of which, the video is making less meaning. Seems like, many have the same issues. As told by many here, I would also emphasize the need for more practice questions."
      },
      {
        "user_id": null,
        "content": "Participants of this course should express their experience so that a more meaningful content can be created and provided to us as supplementary. From lec video it is clear that the recording were made around july so they had around half an year time to work on it.\nThe other problem is, there is no visible resource to get our hands on experience."
      },
      {
        "user_id": null,
        "content": "I also feel the same. but I think with further weeks the course will become more interesting."
      },
      {
        "user_id": null,
        "content": "As my peers said i also feels the same way but i don’t have thought of dropping course rather i wanted some more content to add from IITM side to make the students more comfortable in this journey."
      },
      {
        "user_id": null,
        "content": "well, my choice of dropping might be wrong…but, guided by the following factors.\nThe recording was perhaps done much earlier as\n@CKPIITM\npointed out in his reply, and so chances are most of it would’ve been already recorded.  So, lesser chances to re-record them.\nThere are no live sessions planned yet for this course… the absence of enough sessions (especially given that it’s a 2-credit course) will worsen the situation.\nFinally, I feel I might be able to better appreciate the technicalities and jargon if I finish all other ML courses before taking this up."
      },
      {
        "user_id": null,
        "content": "Imagine if your reason doesn’t get resolved even after all ML courses are over then in that case you will underutilize your time. So I would suggest don’t think of dropping, it is just a course and we just need to pass it and leverage this knowledge to search for better resources and learning material.\n@Anand"
      },
      {
        "user_id": null,
        "content": "CKPIITM:\nI know I can pass any course but I don’t just wanna pass without any concrete learning.\nwasn’t it you who wrote this earlier"
      },
      {
        "user_id": null,
        "content": "But this will not lead me to dropping either. I always find ways to learn.\nI start with expectation and then start my own search for knowledge."
      },
      {
        "user_id": null,
        "content": "I certainly differ from the point of view of the conversation going on in this thread.\nIn my opinion, I am thinking this first week of content as to understand how the problems or objective come from a company which needs these models to implemented. It is more of a professional view rather than a student view. We need to first understand the problem and then start the solution rather than just jumping on to modelling each question."
      },
      {
        "user_id": null,
        "content": "I also found 1st week content engaging and practical. Maybe I will get few questions wrong,but I feel the concept of discovering the problem was well introduced."
      },
      {
        "user_id": null,
        "content": "I too find content of week 1 engaging and practical. I agree with\n@anand095\nand\n@akruti\n."
      },
      {
        "user_id": null,
        "content": "Interesting!  Just this morning, during my morning walk I was thinking how each of us is different in our outlook, our potential, how we realize it, how we’re challenged…and the recent posts show that we indeed are different!  It’s important that none of us stay put on what works for us and what we think is right, but be willing to see the other point of view too…\nI think I’m starting to understand the other points of view…well I’m trying to"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/about-the-tools-in-data-science-category/23335/42",
    "posts": [
      {
        "user_id": null,
        "content": "Hey guys, thank you everyone for voicing out your opinions and perspective in a healthy manner. I really appreciate it. I understand it might start to sound like greek and latin for some of you, but we intentionally made the decision to have ML foundations as co-requisite. Because you can learn the theory and try to visit back and connect with the practice (tools) part. Some pointers which could be helpful for all of you having different perspectives (both positive and negative) -\nWhat is the benefit of this course? - passing this course would definitely make you industry ready. And Anand S, who himself is a very accomplished Data Scientist wanted to give the real flavour of how you would be working in Industry (no spoon-feeding, but giving you directions). Most examinations will be open book, open internet or take home.\nWe will share all the resources (codes, excel, etc.). You can download those supplementary materials from the drive link in course contents page.\nThere will be youtube live sessions every week and the calendar will be shared soon. Please used these live sessions if you need more help or guidance.\nAll the instructors in this course are well accomplished data scientists working in industry and most of them also teach in different IITs/IIMs as faculty. So my humble request is to give them all a bit of respect as some of you are bluntly rude.\nDefinitely this course will be different from other courses because this is going to be an applied course and the idea is to make you know the different quantum of things we could do in data science. I do not think you would be Industry ready unless you get comfortable with this course honestly. Because this is the reality, this is how things are going to be once you interview for or get onboarded as DS.\nThe materials and case studies are so meticulously curated just for the purpose this course in the past 8 months. They are so valuable and try to explore use the help of live sessions to get your issues sorted out.\nUse the Youtube live sessions to the fullest those whoever need more help with this course. We would be more than happy to help. Let’s respect each other and that’s a fair expectation I guess. Thanks!"
      },
      {
        "user_id": null,
        "content": "Good evening\n@maheshbalan\nPoints 2 and 3 in your message will be useful and I look forward to these.\nI have separately raised another query that some of the tools being used are Gramener products.  Would you kindly assist in letting us know how we can get access to the products so that we can start playing around with them?\nregards"
      },
      {
        "user_id": null,
        "content": "Thank you for raising this, we will talk to the course faculty and request for access. Thanks"
      },
      {
        "user_id": null,
        "content": "Well, here’s an admission…I stand corrected on my opinion about the TDS course.\nwith each day watching and learning from the course, I’m absolutely excited to see the content!  It’s presented so well, so well, that I can vouch that I’ve never seen anything like this before…\nI was totally wrong and wanted to let everyone here know how perspectives can change in a matter of just 2 weeks.\nHaving said all this, I still believe the first video in this course was misplaced, and that was perhaps a very bad decision by the editors…not the course team.  If my blunt comments hurt anyone, which I’m sure it did, I apologize\n@maheshbalan"
      },
      {
        "user_id": null,
        "content": "Hi Anand, thank you for your positive feedback. We have to admit that some of the concerns raised by the students here helped us restructure things efficiently. Thanks for letting us know and please continue to raise concerns if you have any going forward, It will help us fine tune this course further.\nThanks,\nMahesh"
      },
      {
        "user_id": null,
        "content": "As things will get structured, and the motive gets  clearer to participant of this course, opinion will change, The video introduction was indeed exciting, but we as participant, who also want to score in assignment and all try to map content with ability to solve the questions and then internally rate as sufficient or insufficient, it is not about how exciting it was rather how helpful it was to score better. We don’t know how industry will judge at first, with marks, excitement, ability to learn new things and many other parameters, so when we watch video we expect it to moving around questions being asked.\nIt is like we\noverfit ourselves to video content\n, but\nunderfit the assignment content\n. So some\nregularisations\n, you as a team have to add to make it just\nright fit\n.\nWhether it’s\n@Anand\nor people like me, who themselves are teachers for more than a decade, can see the gap more profound than others and are vocal at the same time.\nTrust us we are the one who reverses our opinions if things are started to get fine tuned without any hesitation or apprehension.\nAnd surely, we are not doubting the intent of IITM, they are for sure imparting best of knowledge to mere mortals like us. We are just fortunate in many ways and thankful to IITM.\nTake our responses just as feedback. And make this course truly world class."
      },
      {
        "user_id": null,
        "content": "Hi, can anyone explain how to calculate regression problem using excel"
      },
      {
        "user_id": null,
        "content": "@bidisha143\n, please make a separate post on this; this thread is not a fit for your query."
      },
      {
        "user_id": null,
        "content": "You have to install DataToolPk plug-in from option settings. Then go to Data ribbon of excel from there click data analysis. Find regression click and select data range from excel and you are done."
      },
      {
        "user_id": null,
        "content": "Yes i enabled that…but the problem comes after that…\nIn the sum , they have given only one input /independent variable. Like the sum was to find the ration between to currencies how to get the calculation for only one independent variable?"
      },
      {
        "user_id": null,
        "content": "Use correlation table instead of regression. Use correl function.  In case it ask for two range give the same range twice.\n@bidisha143"
      },
      {
        "user_id": null,
        "content": "Okay giving same range twice might resolve the issue. Thank you."
      },
      {
        "user_id": null,
        "content": "If it solves the issue plz mark as solution. It helps other learners."
      },
      {
        "user_id": null,
        "content": "How to check the answers"
      },
      {
        "user_id": null,
        "content": "In the orientation it was clearly stated that  is no end term eligibility for this course and in the graded document it is stated that 5/8 and because of this i havent submitted earlier week assignments and now it is stated that only starting 5 are considered now i am ineligible for end term\nplease help me out in this\ngiven that i have attempted and scored well in ROE and also submitted both the projects"
      },
      {
        "user_id": null,
        "content": "@maheshbalan\nSuggestion :\nMLP\nshould be made a corequisite for this course.\nWhy do I say this?\nI took “Tools in Data Science” course last term.  And I found it very hard to follow a lot of concepts.  But now (I’ve taken MLP course for this term),  I’m able to appreciate and understand the content better. Because now I have a basic understanding of different Machine Learning Models and I know where to apply what.\nFor example in TDS course week 5, we were taught about Pycaret, KMeans clustering and image classification. A lot of it went above my head because I didn’t know what RandomForestClassifier, LogisticRegression or KMeans Classifier was.\nI wish I had taken TDS after completing all ML courses. It would have helped me to understand a lot of DS tools better."
      },
      {
        "user_id": null,
        "content": "Sir\nI attended End Term Exam on 28 April 2024 in TDS.\nI got WA grade in TDS even though I attended for End Term Exam. Could you clarify this for me?\nPlease download Screen Shot below\nSincerely\n//Student//\nUploading: Screenshot_2024-05-07-08-27-18-567_com.android.chrome.jpg…\n21f1004796@ds.study.iitm.ac.in"
      },
      {
        "user_id": null,
        "content": "@carlton\nI was trying to view a session, but since youtube is very distracting I tried to embed it on a site, but it throws this error\nimage\n2852×1564 131 KB\nWebsite Where I am embedding\nVideo I am trying to watch\nIf possible, please fix this since the youtube as a platform is distracting and has many ads, even though the channel is not monitized."
      },
      {
        "user_id": null,
        "content": "@23f2003845\nI will have to get authorisation from the operations to allow embedding you tube videos. This was a deliberate choice as the content is strictly speaking owned by IITM. Embeddings may allow others to monetise content without the appropriate permissions.\nI will enquire on your behalf. I accept that not every channel follows the directives properly, so you might find it possible to embed other channel videos from IITM, but I can only go by the agreed upon protocols.\nI know that’s not much comfort, but if its possible, I will amend the permissions.\nKind regards"
      },
      {
        "user_id": null,
        "content": "I purely understand that the content solely belongs to IITM and I truly adhere to it.\ncarlton:\nEmbeddings may allow others to monetise content without the appropriate permissions.\nI can’t personally think of any way one can do this, but it’s completely upto to the operations team.\nI ask for this permission as youtube can be quite distracting and getting rid of advertisements either require an adblocker that cause some trouble once in 2 weeks, even though they don’t turn of recommendations and hence the procrastination. Embedding is another way which can stop the recommendations and the advertisements.\nHope to hear soon,\nRegards"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/project1-virtual-ta-discussion-thread-tds-may-2025/176077/472",
    "posts": [
      {
        "user_id": null,
        "content": "Render API doesn’t support image processing . What should I do."
      },
      {
        "user_id": null,
        "content": "image\n1311×446 21.7 KB\nwhy i still got failed to fetch error in tds course page"
      },
      {
        "user_id": null,
        "content": "What error you are getting? Capture the network traffic as fetch function and then paste it in the the developer tools console to find exatly what is the issue, you will be able to resolve it."
      },
      {
        "user_id": null,
        "content": "I am also getting this same error. Did you resolve this issue?"
      },
      {
        "user_id": null,
        "content": "I am also facing this same error. Did u resolve it?"
      },
      {
        "user_id": null,
        "content": "@Jivraj\n@carlton\nMy Code is correct working for the text but when for images i am not sure how my models works also it was mentioned that in the main evaluation images will also be sent so i am worried in which format will they be sent url or path or which since the promptfoo file one is not working fine for my code , Kindly inform us soon about the image usage and criteria for evaluation so that we can test is our model doing right or wrong , if there will be issue we will improve it . Kindly Inform and guide us about the same ."
      },
      {
        "user_id": null,
        "content": "Nope not yet. I have added my API key to the yaml file, but it still doesn’t work"
      },
      {
        "user_id": null,
        "content": "While deploying my prj in vercel i got “A serverlrss function has exceeded the unzipped maximum size of 250 MB” How could i solve this?"
      },
      {
        "user_id": null,
        "content": "This coming due to the modules present requirements.txt remove the Unnecessary modules and make a .vercelignore file and ignore every file except the main python file and the embeddings dataset , do these if still the memory is excedding then user another options for deployment ."
      },
      {
        "user_id": null,
        "content": "Is render good for deploying my project"
      },
      {
        "user_id": null,
        "content": "Yes you can , its all up to you but take care of sleeping time"
      },
      {
        "user_id": null,
        "content": "Have you enabled CORS on your FASTAPI to serve request from other domains? Else this will not work."
      },
      {
        "user_id": null,
        "content": "Bro same problem also with me , app ki solve hoo gayi kay"
      },
      {
        "user_id": null,
        "content": "By default it is using gpt-4.1 as previous post of sir says"
      },
      {
        "user_id": null,
        "content": "@carlton\n@Jivraj\n@s.anand\nafter 18th, how long till evaluation are over? Will they be done in a month? I’m hosting it on AWS and I’m getting billed for it. Vercel didn’t work for me and render didn’t handle so much data. Can you please tell?"
      },
      {
        "user_id": null,
        "content": "failed to fetch error in exam portal .But i test my url in browser it shows status:ok."
      },
      {
        "user_id": null,
        "content": "What is the fetch error your getting can you please post the exact error? Opening the developer tools and watching the console log can help."
      },
      {
        "user_id": null,
        "content": "Possibly CORS issue.. Enable CORS in API if already not done..\nif it’s on vercel then turn off deployment protection to remove any authentication errors"
      },
      {
        "user_id": null,
        "content": "@carlton\n@Jivraj\nHello\nI have another question on testing… the sample YAML file for each var in tests contains 2 condition one is around is LLM-rubic and another is if link contains…\nwhen you will test… will you be having similar 2-2 conditions for each test & if so would pass/fail will be decided if both 2 conditions are met?\nbecause sometime our api responce may contain the required link but the answer text may not be meet due to LLM variability"
      },
      {
        "user_id": null,
        "content": "How will the tests be run for the evaluation with promptfoo file or a curl requests as i am facing the issue the file is running corrcetly on local machine , promptfoo yaml and curl both but when deploying on huggingface only curl works correctly and the promptfoo file is uable to get the image correctly"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/hoe-to-get-disclosure-api/179010",
    "posts": [
      {
        "user_id": null,
        "content": "can anyone help  with this problem"
      },
      {
        "user_id": null,
        "content": "discourse api is only for admins i guess but we need it for the project\n@pds_staff\n@andrew\nplease help sir"
      },
      {
        "user_id": null,
        "content": "Please watch Project1 sessions present on youtube, First session for project 1 covers how to access discourse api’s and get thread data."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/cors-settings-for-the-deployed-project/179183/1",
    "posts": [
      {
        "user_id": null,
        "content": "I have allowed\nhttps://exam.sanand.workers.dev\nin CORS of TDS project 1. Is this enough or should I give access to every site i.e [“*”] ?"
      },
      {
        "user_id": null,
        "content": "@carlton\nsir, please clarify"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/doubt-regarding-promptfoo-in-tds-project-1/179012/1",
    "posts": [
      {
        "user_id": null,
        "content": "My promptfoo is showing this output when I run it, but while using curl, i get appropriate response. What should I do?\nScreenshot 2025-06-12 at 11.38.44 PM\n3024×434 172 KB\nScreenshot 2025-06-12 at 11.37.17 PM\n1272×1490 151 KB"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/tds-project-1-2025/179103/3",
    "posts": [
      {
        "user_id": null,
        "content": "I’ve watched the YouTube sessions for Project 1, but I’m feeling quite confused. I’ve managed to scrape data from Discourse, and the content is now saved in multiple files. I’ve converted these files into\n.md\n(Markdown) format, but I’m having trouble handling the images — I’m not able to extract or display them properly.   Can anyone help?"
      },
      {
        "user_id": null,
        "content": "Can you please clarify how you scraped the data . I am not able to do it. Please Help me."
      },
      {
        "user_id": null,
        "content": "You can watch project sessions of tds in youtube playlist. They have mentioned and shown example of how to scrape the data."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/project-1-of-tools-in-data-science/179210/1",
    "posts": [
      {
        "user_id": null,
        "content": "What will be the output of curl statement?"
      },
      {
        "user_id": null,
        "content": "@archie123\nTopic moved to the appropriate category in order to get faster responses.\nPlease make it easier for others to help you, by ensuring that topics are created in the correct categories."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/cors-settings-for-the-deployed-project/179183",
    "posts": [
      {
        "user_id": null,
        "content": "I have allowed\nhttps://exam.sanand.workers.dev\nin CORS of TDS project 1. Is this enough or should I give access to every site i.e [“*”] ?"
      },
      {
        "user_id": null,
        "content": "@carlton\nsir, please clarify"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/project-1-submission-deadline/179145",
    "posts": [
      {
        "user_id": null,
        "content": "@carlton\nSir could you please extend the deadline for the submission of the project-1 by one more day."
      },
      {
        "user_id": null,
        "content": "Sir, Please check possibility of few days extension as some of the tasks requires throttling and unable to get it done on time."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/promptfoo-yaml-not-fetching-results/179348/1",
    "posts": [
      {
        "user_id": null,
        "content": "whenever i use curl to ask questions it fetches results fine however the same questions when asked by promptfoo wont get any results and “say i could not find”\nScreenshot 2025-06-16 at 8.46.52 PM\n1016×540 54.3 KB"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/project-1-submission-deadline/179145/2",
    "posts": [
      {
        "user_id": null,
        "content": "@carlton\nSir could you please extend the deadline for the submission of the project-1 by one more day."
      },
      {
        "user_id": null,
        "content": "Sir, Please check possibility of few days extension as some of the tasks requires throttling and unable to get it done on time."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/tds-references-guidelines/67216",
    "posts": [
      {
        "user_id": null,
        "content": "Course Portal\nPublic Course Portal Link\nInstructors\nPrasanna -\n@iamprasna\nCarlton -\n@carlton\nTags Usage\nPractice Question -\nWeek-num\nPractice-question\nGraded Question -\nWeek-num\nGraded-question\nOperational -\noperational\nExam -\nquiz\nProject -\nproject-num\nTerm -\ntermNum-YYYY\nCalendar\nCourse/subject calendar\nImportant Links\nGrading Document\nAnnouncement Group\nOfficial YouTube channel\nPurpose of ROE\nCourse Feedback\nHere’s students’ feedback:\nIt\nused\nto be an easy course until 2024.\n#\n#\n#\nNow it’s hard and covers more. Take it in your last semester if possible.\n#\n#\n#\nPlan extra time. It takes more time than typical 3-credit courses.\n#\n#\n#\nLLMs grade you – unpredictably.\n#\n#\nThe ROE is hard.\n#"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/github-account-made-using-the-iitm-email-id-keeps-getting-blocked/179166",
    "posts": [
      {
        "user_id": null,
        "content": "Hello everyone,\nI have earlier submitted the project1 successfully and saved it to. Today i just wanted to verify if my submissions were still working as the project said (The URL should be accessible when the project team evaluates your submission.)\nThe API endpoint which i depolyed on Render is still working just fine\n(takes a little while when tested after a while for the application to start)\nbut the github repo which i used to deploy the project is not accesibible\nThis is second time my github account got blocked.\nAnd i am also unable to unblock it today as i have already surpassed the sms otp limit for the day (it was going to spam\n)\nPlease let me know if i will be scored fairly"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/api-key-error/178898/1",
    "posts": [
      {
        "user_id": null,
        "content": "(venv) C:\\Users\\User\\Desktop\\TDS Folder>python scrape/embed_documents.py\nEmbedding documents: 0it [00:00, ?it/s]\nError getting embedding: Error code: 401 - {‘error’: {‘message’: ‘Your authentication token is\nnot from a valid issuer.’, ‘type’: ‘invalid_request_error’, ‘param’: None, ‘code’: ‘invalid_issuer’}}\nEmbedding documents: 1it [00:00,  1.26it/s]\nError getting embedding: Error code: 401 - {‘error’: {‘message’: ‘Your authentication token\nis not from a valid issuer.’, ‘type’: ‘invalid_request_error’, ‘param’: None, ‘code’: ‘invalid_issuer’}}\nEmbedding documents: 2it [00:01,  1.95it/s]\nError getting embedding: Error code: 401 - {‘error’: {‘message’: ‘Your authentication token\nis not from a valid issuer.’, ‘type’: ‘invalid_request_error’, ‘param’: None, ‘code’: ‘invalid_issuer’}}\nEmbedding documents: 3it [00:01,  2.08it/s]"
      },
      {
        "user_id": null,
        "content": "description: \"TDS Virtual TA Project Sample (but not the actual evaluation) Questions\"\n\nproviders:\n  - id: https\n    config:\n      url: YOUR_API_ENDPOINT # Replace this with your API endpoint\n      method: POST\n      headers:\n        Content-Type: application/json\n      body: |\n        {\n          \"question\": \"{{ question }}\"{% if image %},\n          \"image\": \"{{ image }}\"{% endif %}\n        }\n      transformResponse: json\n\n# Ensure JSON schema\ndefaultTest:\n  options:\n    provider:\n      id: https\n      config:\n        url: https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\n        method: POST\n        headers:\n          Content-Type: application/json\n          Authorization: Bearer YOUR_API_KEY  # Replace with your token\n        body: |\n          {\n            \"model\": \"gpt-4o-mini\",\n            \"messages\": [\n              {\"role\": \"system\", \"content\": \"You are an evaluator that checks if an output meets specific criteria. Analyze the output based on the given rubric and respond with a JSON object containing {\\\"reason\\\": \\\"your analysis\\\", \\\"score\\\": number between 0.0 and 1.0, \\\"pass\\\": true/false}.\"},\n              {\"role\": \"user\", \"content\": \"Output to evaluate: {{ output }}\\n\\nRubric: {{ rubric }}\"}\n            ],\n            \"temperature\": 0\n          }\n        transformResponse: json\n\n  assert:\n    - type: is-json\n      value:\n        type: object\n        required: [answer, links]\n        properties:\n          answer: { type: string }\n          links:\n            type: array\n            items:\n              type: object\n              required: [url, text]\n              properties:\n                url: { type: string }\n                text: { type: string }\n\ntests:\n  - vars:\n      question: The question asks to use gpt-3.5-turbo-0125 model but the ai-proxy provided by Anand sir only supports gpt-4o-mini. So should we just use gpt-4o-mini or use the OpenAI API for gpt3.5 turbo?\n      image: file://project-tds-virtual-ta-q1.webp\n      link: https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Clarifies use of gpt-3.5-turbo-0125 not gpt-4o-mini\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939\n\n  - vars:\n      question: If a student scores 10/10 on GA4 as well as a bonus, how would it appear on the dashboard?\n      link: https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-jan-2025/165959/388\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Mentions the dashboard showing \"110\"\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-jan-2025/165959\n  - vars:\n      question: I know Docker but have not used Podman before. Should I use Docker for this course?\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Recommends Podman for the course\n      - type: llm-rubric\n        transform: output.answer\n        value: Mentions that Docker is acceptable\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://tds.s-anand.net/#/docker\n  - vars:\n      question: When is the TDS Sep 2025 end-term exam?\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Says it doesn't know (since this information is not available yet)\n\nwriteLatestResults: true\n\ncommandLineOptions:\n  cache: true\nMake sure to replace “YOUR_API_KEY” with the API key that you have and “YOUR_API_ENDPOINT” with the URL and port you are running your API.\nNo need to keep the url and api_key in quotes, just paste them as it is."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/hoe-to-get-disclosure-api/179010/1",
    "posts": [
      {
        "user_id": null,
        "content": "can anyone help  with this problem"
      },
      {
        "user_id": null,
        "content": "discourse api is only for admins i guess but we need it for the project\n@pds_staff\n@andrew\nplease help sir"
      },
      {
        "user_id": null,
        "content": "Please watch Project1 sessions present on youtube, First session for project 1 covers how to access discourse api’s and get thread data."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/image-size-issue-with-the-railway-app-deployment-made/179213",
    "posts": [
      {
        "user_id": null,
        "content": "I have tried to deploy the app to\nrailway.com\nbut getting the error like this\nimage\n1917×945 65.7 KB\nIssue witn the image build, but we don’t have any control over it..\nAny other deployment resources??"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/project-1-submission-deadline/179145/1",
    "posts": [
      {
        "user_id": null,
        "content": "@carlton\nSir could you please extend the deadline for the submission of the project-1 by one more day."
      },
      {
        "user_id": null,
        "content": "Sir, Please check possibility of few days extension as some of the tasks requires throttling and unable to get it done on time."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/drop-course-window/179104",
    "posts": [
      {
        "user_id": null,
        "content": "@carlton\nsir I’m unable to continue with the course, is it possible to drop course somehow, the option is not visible anywhere. Please guide.\nRegards\nNitin Dixit\n23f2005404"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/getting-an-api-key-error-upon-running-npx-y-promptfoo-eval-config-project-tds-virtual-ta-promptfoo-yaml/178878/1",
    "posts": [
      {
        "user_id": null,
        "content": "[FAIL] API error: 401  Unauthorized  {“error”:{“message”:\"Inc… API key provided: sk-proj-*************** You can find your API key at\nhttps://platform.openai\n.…"
      },
      {
        "user_id": null,
        "content": "@HritikRoshan_HRM\nsir\n@carlton\nsir could you pls help"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/submissions-of-weekly-graded-assignment-of-tds/178618/1",
    "posts": [
      {
        "user_id": null,
        "content": "@Jivraj\n@21f3002441\nI have submitted the weekly graded assignments for Tools in Data science, from the correct google account and yet it has been showing not submitted from the past three weeks. Could you help me with this?\ncomplaint1\n900×874 122 KB\n, this is shown and yet it is showing not submitted in the grades section\nsimilar problem for all three weeks. Please let me know"
      },
      {
        "user_id": null,
        "content": "Hi\n@24f1002463\nWhat do you see on course page ?\nNptel Seekh"
      },
      {
        "user_id": null,
        "content": "Thank you. There seems to be a glitch, because now, marks are visible on the course page but when I check grades individually for the course, it still says not submitted."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/unable-to-deploy-api-on-render/179292",
    "posts": [
      {
        "user_id": null,
        "content": "this is my render log\nERROR: Exception:\nJun 16 05:06:01 AM\nTraceback (most recent call last):\nJun 16 05:06:01 AM\nFile “/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/cli/base_command.py”, line 105, in _run_wrapper\nJun 16 05:06:01 AM\nstatus = _inner_run()\nJun 16 05:06:01 AM\nFile “/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/cli/base_command.py”, line 96, in _inner_run\nJun 16 05:06:01 AM\nreturn self.run(options, args)\nJun 16 05:06:01 AM\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/cli/req_command.py\", line 68, in wrapper\n\nJun 16 05:06:01 AM\n\nreturn func(self, options, args)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/commands/install.py\", line 387, in run\n\nJun 16 05:06:01 AM\n\nrequirement_set = resolver.resolve(\n\nJun 16 05:06:01 AM\n\nreqs, check_supported_wheels=not options.target_dir\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 96, in resolve\n\nJun 16 05:06:01 AM\n\nresult = self._result = resolver.resolve(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\ncollected.requirements, max_rounds=limit_how_complex_resolution_can_be\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 515, in resolve\n\nJun 16 05:06:01 AM\n\nstate = resolution.resolve(requirements, max_rounds=max_rounds)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 388, in resolve\n\nJun 16 05:06:01 AM\n\nself._add_to_criteria(self.state.criteria, r, parent=None)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 141, in _add_to_criteria\n\nJun 16 05:06:01 AM\n\nif not criterion.candidates:\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/structs.py\", line 194, in __bool__\n\nJun 16 05:06:01 AM\n\nreturn bool(self._sequence)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 163, in __bool__\n\nJun 16 05:06:01 AM\n\nself._bool = any(self)\n\nJun 16 05:06:01 AM\n\n~~~^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 147, in <genexpr>\n\nJun 16 05:06:01 AM\n\nreturn (c for c in iterator if id(c) not in self._incompatible_ids)\n\nJun 16 05:06:01 AM\n\n^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 37, in _iter_built\n\nJun 16 05:06:01 AM\n\ncandidate = func()\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 187, in _make_candidate_from_link\n\nJun 16 05:06:01 AM\n\nbase: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nlink, template, name, version\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 233, in _make_base_candidate_from_link\n\nJun 16 05:06:01 AM\n\nself._link_candidate_cache[link] = LinkCandidate(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nlink,\n\nJun 16 05:06:01 AM\n\n^^^^^\n\nJun 16 05:06:01 AM\n\n...<3 lines>...\n\nJun 16 05:06:01 AM\n\nversion=version,\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 306, in __init__\n\nJun 16 05:06:01 AM\n\nsuper().__init__(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nlink=link,\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n...<4 lines>...\n\nJun 16 05:06:01 AM\n\nversion=version,\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 159, in __init__\n\nJun 16 05:06:01 AM\n\nself.dist = self._prepare()\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 236, in _prepare\n\nJun 16 05:06:01 AM\n\ndist = self._prepare_distribution()\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 317, in _prepare_distribution\n\nJun 16 05:06:01 AM\n\nreturn preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 532, in prepare_linked_requirement\n\nJun 16 05:06:01 AM\n\nreturn self._prepare_linked_requirement(req, parallel_builds)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 647, in _prepare_linked_requirement\n\nJun 16 05:06:01 AM\n\ndist = _get_prepared_distribution(\n\nJun 16 05:06:01 AM\n\nreq,\n\nJun 16 05:06:01 AM\n\n...<3 lines>...\n\nJun 16 05:06:01 AM\n\nself.check_build_deps,\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 71, in _get_prepared_distribution\n\nJun 16 05:06:01 AM\n\nabstract_dist.prepare_distribution_metadata(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nfinder, build_isolation, check_build_deps\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 56, in prepare_distribution_metadata\n\nJun 16 05:06:01 AM\n\nself._install_build_reqs(finder)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 126, in _install_build_reqs\n\nJun 16 05:06:01 AM\n\nbuild_reqs = self._get_build_requires_wheel()\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 103, in _get_build_requires_wheel\n\nJun 16 05:06:01 AM\n\nreturn backend.get_requires_for_build_wheel()\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/utils/misc.py\", line 702, in get_requires_for_build_wheel\n\nJun 16 05:06:01 AM\n\nreturn super().get_requires_for_build_wheel(config_settings=cs)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 196, in get_requires_for_build_wheel\n\nJun 16 05:06:01 AM\n\nreturn self._call_hook(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\n\"get_requires_for_build_wheel\", {\"config_settings\": config_settings}\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 402, in _call_hook\n\nJun 16 05:06:01 AM\n\nraise BackendUnavailable(\n\nJun 16 05:06:01 AM\n\n...<4 lines>...\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\npip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'\n\nJun 16 05:06:02 AM\n\n==> Build failed 😞\n\npls help me fix this sir. thank you."
      },
      {
        "user_id": null,
        "content": "(post deleted by author)"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/doubt-regarding-promptfoo-in-tds-project-1/179012",
    "posts": [
      {
        "user_id": null,
        "content": "My promptfoo is showing this output when I run it, but while using curl, i get appropriate response. What should I do?\nScreenshot 2025-06-12 at 11.38.44 PM\n3024×434 172 KB\nScreenshot 2025-06-12 at 11.37.17 PM\n1272×1490 151 KB"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/hoe-to-get-disclosure-api/179010/3",
    "posts": [
      {
        "user_id": null,
        "content": "can anyone help  with this problem"
      },
      {
        "user_id": null,
        "content": "discourse api is only for admins i guess but we need it for the project\n@pds_staff\n@andrew\nplease help sir"
      },
      {
        "user_id": null,
        "content": "Please watch Project1 sessions present on youtube, First session for project 1 covers how to access discourse api’s and get thread data."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/help-required-in-project-1-scrapping-discourse-data/179153/6",
    "posts": [
      {
        "user_id": null,
        "content": "Hello,\nI’m new to coding and still learning. I’m trying to scrape data from a Discourse forum and have identified the relevant API endpoint. However, I’m having trouble with authentication—I keep receiving a 403 error stating that the user is not logged in or doesn’t have permission to perform the action.\nI’ve tried using the most recent cookies from my browser, but I still get the same error. Can someone help me figure out what I’m doing wrong?"
      },
      {
        "user_id": null,
        "content": "Honestly, you must be unintentionally making some sort of a mistake. I will give you a function definition that should work.\nimport\nrequests\ndef\ncreate_session\n():\n\n    domain =\n\"discourse.onlinedegree.iitm.ac.in\"\nsession = requests.Session()\n\n    cookies =\ndict\n(\n\n        _t =\n\"_______________\"\n,\n\n        _forum_session =\n\"_______________\"\n)\nfor\nname, value\nin\ncookies.items():\n\n        session.cookies.\nset\n(name, value, domain=domain)\nreturn\nsession\nUse this\nsession\nobject using\nsession.get(url, headers=headers)\n.\nYou must create a session to mimic a real browser. Good luck!"
      },
      {
        "user_id": null,
        "content": "did u get an api key for discourse to scrape the data can u help me with that\n@23f1000917"
      },
      {
        "user_id": null,
        "content": "i am currently running it in local host 8000 other functionalities are working this is the problem data scraping"
      },
      {
        "user_id": null,
        "content": "Okay, I will explain it to you.\nUpon visiting discourse and signing in with your account, you get ‘cookies’ containing information that can be used to authorize you. These cookies are sent with each subsequent\nrequest\nyou make to discourse, if the website does not recognize these\ncookies\n, they simply reject your request with a status code of 403.\nIf you want to scrape the posts, you need to get these\ncookies\n. So, where are these cookies stored? Well, just sign into discourse with your IITM account (in Chrome). Then, visit the following URL:\nhttps://discourse.onlinedegree.iitm.ac.in/session/current.json\nOnce the page has opened and you can see JSON data, do the following:\nright click > inspect > application > cookies > https://discourse.onlinedegree.iitm.ac.in/\n.\nNow, you will see a bunch of cookies, which are similar to a python dictionary containing key-value pairs. You only care about two such keys, one is\n_t\nand the other one is\n_forum_session\n.\nSave the value of these cookie keys in a python file like\nmy_cookies.py\n:\n# my_cookies.py\n_t =\n\"your _t cookie\"\n_forum_session =\n\"your _forum_session cookie\"\nNow, these can be imported into other files using:\nfrom\nmy_cookies\nimport\n_t, _forum_session\n\nauth_cookie:\ndict\n= {\n'_t'\n: _t ,\n'_forum_session'\n: _forum_session }\nNote that these\ncookies keep changing\n, when you make new requests you get different values that replace the current values of your\nsession\n. You can think of the session as a user.\nNow, look at my previous reply:\nhttps://discourse.onlinedegree.iitm.ac.in/t/help-required-in-project-1-scrapping-discourse-data/179153/2?u=23f1000917\nThe\nrequests\nmodule is used to send requests to websites in python.  You need to install it using\npip install requests\n. You create a session object and add your cookies in it. This automatically handles the\nchanging and replacement of cookie values\nwhen you make requests.\nSearch for a tutorial on the\nrequests\nmodule to understand how to make requests using it. Just know that you can do the something like this:\nimport\nrequests \n\nURL =\n\"https://example.com/latest_threads.json\"\nsession = requests.Session()\nresponse = session.get(URL)\nif\nresponse.status_code=\n200\n:\n    data = response.json()\n# get json data\nLastly, watch the live sessions conducted by IITM on 10th June and next few days. You can find them in your google calendar."
      },
      {
        "user_id": null,
        "content": "@23f1000917\nthanks bro will try this out"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/unable-to-deploy-api-on-render/179292/2",
    "posts": [
      {
        "user_id": null,
        "content": "this is my render log\nERROR: Exception:\nJun 16 05:06:01 AM\nTraceback (most recent call last):\nJun 16 05:06:01 AM\nFile “/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/cli/base_command.py”, line 105, in _run_wrapper\nJun 16 05:06:01 AM\nstatus = _inner_run()\nJun 16 05:06:01 AM\nFile “/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/cli/base_command.py”, line 96, in _inner_run\nJun 16 05:06:01 AM\nreturn self.run(options, args)\nJun 16 05:06:01 AM\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/cli/req_command.py\", line 68, in wrapper\n\nJun 16 05:06:01 AM\n\nreturn func(self, options, args)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/commands/install.py\", line 387, in run\n\nJun 16 05:06:01 AM\n\nrequirement_set = resolver.resolve(\n\nJun 16 05:06:01 AM\n\nreqs, check_supported_wheels=not options.target_dir\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 96, in resolve\n\nJun 16 05:06:01 AM\n\nresult = self._result = resolver.resolve(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\ncollected.requirements, max_rounds=limit_how_complex_resolution_can_be\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 515, in resolve\n\nJun 16 05:06:01 AM\n\nstate = resolution.resolve(requirements, max_rounds=max_rounds)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 388, in resolve\n\nJun 16 05:06:01 AM\n\nself._add_to_criteria(self.state.criteria, r, parent=None)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 141, in _add_to_criteria\n\nJun 16 05:06:01 AM\n\nif not criterion.candidates:\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/structs.py\", line 194, in __bool__\n\nJun 16 05:06:01 AM\n\nreturn bool(self._sequence)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 163, in __bool__\n\nJun 16 05:06:01 AM\n\nself._bool = any(self)\n\nJun 16 05:06:01 AM\n\n~~~^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 147, in <genexpr>\n\nJun 16 05:06:01 AM\n\nreturn (c for c in iterator if id(c) not in self._incompatible_ids)\n\nJun 16 05:06:01 AM\n\n^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 37, in _iter_built\n\nJun 16 05:06:01 AM\n\ncandidate = func()\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 187, in _make_candidate_from_link\n\nJun 16 05:06:01 AM\n\nbase: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nlink, template, name, version\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 233, in _make_base_candidate_from_link\n\nJun 16 05:06:01 AM\n\nself._link_candidate_cache[link] = LinkCandidate(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nlink,\n\nJun 16 05:06:01 AM\n\n^^^^^\n\nJun 16 05:06:01 AM\n\n...<3 lines>...\n\nJun 16 05:06:01 AM\n\nversion=version,\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 306, in __init__\n\nJun 16 05:06:01 AM\n\nsuper().__init__(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nlink=link,\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n...<4 lines>...\n\nJun 16 05:06:01 AM\n\nversion=version,\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 159, in __init__\n\nJun 16 05:06:01 AM\n\nself.dist = self._prepare()\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 236, in _prepare\n\nJun 16 05:06:01 AM\n\ndist = self._prepare_distribution()\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 317, in _prepare_distribution\n\nJun 16 05:06:01 AM\n\nreturn preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 532, in prepare_linked_requirement\n\nJun 16 05:06:01 AM\n\nreturn self._prepare_linked_requirement(req, parallel_builds)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 647, in _prepare_linked_requirement\n\nJun 16 05:06:01 AM\n\ndist = _get_prepared_distribution(\n\nJun 16 05:06:01 AM\n\nreq,\n\nJun 16 05:06:01 AM\n\n...<3 lines>...\n\nJun 16 05:06:01 AM\n\nself.check_build_deps,\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 71, in _get_prepared_distribution\n\nJun 16 05:06:01 AM\n\nabstract_dist.prepare_distribution_metadata(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nfinder, build_isolation, check_build_deps\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 56, in prepare_distribution_metadata\n\nJun 16 05:06:01 AM\n\nself._install_build_reqs(finder)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 126, in _install_build_reqs\n\nJun 16 05:06:01 AM\n\nbuild_reqs = self._get_build_requires_wheel()\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 103, in _get_build_requires_wheel\n\nJun 16 05:06:01 AM\n\nreturn backend.get_requires_for_build_wheel()\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/utils/misc.py\", line 702, in get_requires_for_build_wheel\n\nJun 16 05:06:01 AM\n\nreturn super().get_requires_for_build_wheel(config_settings=cs)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 196, in get_requires_for_build_wheel\n\nJun 16 05:06:01 AM\n\nreturn self._call_hook(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\n\"get_requires_for_build_wheel\", {\"config_settings\": config_settings}\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 402, in _call_hook\n\nJun 16 05:06:01 AM\n\nraise BackendUnavailable(\n\nJun 16 05:06:01 AM\n\n...<4 lines>...\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\npip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'\n\nJun 16 05:06:02 AM\n\n==> Build failed 😞\n\npls help me fix this sir. thank you."
      },
      {
        "user_id": null,
        "content": "(post deleted by author)"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939/1",
    "posts": [
      {
        "user_id": null,
        "content": "image\n756×295 19.5 KB\nThe question asks to use gpt-3.5-turbo-0125 model but the ai-proxy provided by Anand sir only supports gpt-4o-mini. So should we just use gpt-4o-mini or use the OpenAI API for gpt3.5 turbo?\n@carlton"
      },
      {
        "user_id": null,
        "content": "I tried gpt-3.5-turbo-0125 with python’s tiktoken library , I got a different value for prompt token compared gpt-4o-mini from the proxy api."
      },
      {
        "user_id": null,
        "content": "My understanding is that you just have to use a tokenizer, similar to what Prof. Anand used, to get the number of tokens and multiply that by the given rate."
      },
      {
        "user_id": null,
        "content": "Use the model that’s mentioned in the question."
      },
      {
        "user_id": null,
        "content": "The answer should be 0.00165 right."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/tds-references-guidelines/67216/5",
    "posts": [
      {
        "user_id": null,
        "content": "Course Portal\nPublic Course Portal Link\nInstructors\nPrasanna -\n@iamprasna\nCarlton -\n@carlton\nTags Usage\nPractice Question -\nWeek-num\nPractice-question\nGraded Question -\nWeek-num\nGraded-question\nOperational -\noperational\nExam -\nquiz\nProject -\nproject-num\nTerm -\ntermNum-YYYY\nCalendar\nCourse/subject calendar\nImportant Links\nGrading Document\nAnnouncement Group\nOfficial YouTube channel\nPurpose of ROE\nCourse Feedback\nHere’s students’ feedback:\nIt\nused\nto be an easy course until 2024.\n#\n#\n#\nNow it’s hard and covers more. Take it in your last semester if possible.\n#\n#\n#\nPlan extra time. It takes more time than typical 3-credit courses.\n#\n#\n#\nLLMs grade you – unpredictably.\n#\n#\nThe ROE is hard.\n#"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/about-the-tools-in-data-science-category/23335",
    "posts": [
      {
        "user_id": null,
        "content": "This category is created to address\nsubject-specific queries\nrelated to\nTools in Data Science\n- Why should people use this category? What is it for?\nThe larger goal of the Discourse forum is to act as a Knowledge base for the course. You can make this more productive by\nElaborating your question sufficiently and supporting it with steps that you have already tried at your end before posting this question\nSharing additional content or explanations related to the topic being discussed\n-  Are there any rules for posting in this category?\nBefore you create a new post,\nreview the existing threads\nto see if there are already highly similar or identical postings. Discourse will suggest similar posts once you start typing titles\nTag the post appropriately\nso that it gets indexed correctly in our Knowledge Base. For instance, if your query is on an Activity Question in Week 1 then use the tags\n#\nactivity-question\n,\n#\nweek-1\nProvide a meaningful title to your post\nthat contains the topic/details of your query so that it can be searched by others easily. For instance: Do not use the titles like\n“AQ1.1 Q3”\nwhich just gives question number alone.  Instead use a more meaningful title like -\n“Need help in calculating the\nN\nt\nh\nN^{th}\nN\nt\nh\nprime number”\nType in your question and explanations\nrather than pasting images or screenshots.\n- What is NOT Permitted in this category?\nBeing argumentative or sarcastic\nUse of abusive/strong language\nPosting support/logistics related query\nUnnecessarily tagging Faculty/Instructors in posts\nPosting Solutions or discussing solutions to graded assignments\n- Who will be moderating the content in this forum?\nThe foum will be moderated by Course Instructors. They will have the authority to decide whether a post violates forum rules/guidelines. You can flag/report any such violations that you observe by clicking on\nicon on the post. Please do mention the reason why you are flagging the topic.\n- What are the disciplinary actions if some one violates the rules and guidelines of the forum?\nThe flagged posts that violates forum rules/guidelines will be hidden. Repeated violation of the rules can result in the offender being removal from the forum."
      },
      {
        "user_id": null,
        "content": "Can some course instructor talk more about the Discover the problem statement ?"
      },
      {
        "user_id": null,
        "content": "From the graded assignment we can’t understand what is right way to think unless we make trial and error. can we have some practice assignment to understand our thinking process is properly aligned or not. With just GA it would be difficult to assess."
      },
      {
        "user_id": null,
        "content": "Apart from what\n@CKPIITM\nobserved about this course, here’s my first impression of this course…Granted, it has been only a week, but I think I must go ahead anyway…\nThe week-1 clearly shows a lack of planning, from the program as well as the specific course perspective.  It starts off with an example that completely caught me off-guard.  The first video discussed an example that left me wondering why is the instructor even discussing all of that, at this point.  What’s the context and the motivation?  Moreover, every slide is filled to the brim with text.  Can’t decide whether to read it or listen to the speaker.  Neither does give me much understanding anyway.  It was filled with terminology that I’m yet to pick up.  The speaker didn’t apparently know much about who the audience is, and what are they aware of, and what they aren’t…In short, it failed to implement any of the very matter it speaks of - Understanding the problem.\nSummary.  I feel the course is offered too early.  Rather, I took it a little too early.\nDefinitely, I can’t relate to most things the speaker is talking about.  At least, I don’t see how and where the ideas will gel with our program.  I’m sure it does, but now, I don’t know how.\nSorry, I’d never been as critical about anything as this one.  I just had to.  I’m willing to hear different opinions.\nI’m awaiting the announcement from IIT for the course drop."
      },
      {
        "user_id": null,
        "content": "I am totally clue less about the expectation of instructor from the participants of this course. And the question of graded assignment was something, I found myself out of context. I know I can pass any course but I don’t just wanna pass without any concrete learning. The real problem this time is not TIME.\nHopefully courses instructor will guide us through this conundrum."
      },
      {
        "user_id": null,
        "content": "I feel like we need an introduction video of some kind for this. Or it should have been suggested only to those who have completed all the ML courses. From the offset, there are people who don’t know what modelling is, the different kinds of models etc. but there is no explanation for all this. Granted, it was mentioned in the orientation that it would only be tools with no explanation.\nBut I am hopeful that this will get better in the later weeks as this is the only “comprehension” type of week (reminiscent of the english courses lol). The other weeks will all involve practical approach and coding. As long as adequate time is spent on introducing each new thing, I think it should be okay."
      },
      {
        "user_id": null,
        "content": "As of now, I’m set on my mind to drop the course, unless something hopeful turns up next week.  Will continue after all other ML courses are done…"
      },
      {
        "user_id": null,
        "content": "Some sort of introduction would have been better instead of just diving into the topic. Nevertheless, I hope we get practice questions/assignment to comprehend the concepts.\nIn the meantime if anyone gets some sort of resources to practice elsewhere, do share."
      },
      {
        "user_id": null,
        "content": "Adding to the discussion here, I’d also have to say it’s quite the same feeling for me. I got lost while going through the videos. At first, I thought it’s some issue with me, because of which, the video is making less meaning. Seems like, many have the same issues. As told by many here, I would also emphasize the need for more practice questions."
      },
      {
        "user_id": null,
        "content": "Participants of this course should express their experience so that a more meaningful content can be created and provided to us as supplementary. From lec video it is clear that the recording were made around july so they had around half an year time to work on it.\nThe other problem is, there is no visible resource to get our hands on experience."
      },
      {
        "user_id": null,
        "content": "I also feel the same. but I think with further weeks the course will become more interesting."
      },
      {
        "user_id": null,
        "content": "As my peers said i also feels the same way but i don’t have thought of dropping course rather i wanted some more content to add from IITM side to make the students more comfortable in this journey."
      },
      {
        "user_id": null,
        "content": "well, my choice of dropping might be wrong…but, guided by the following factors.\nThe recording was perhaps done much earlier as\n@CKPIITM\npointed out in his reply, and so chances are most of it would’ve been already recorded.  So, lesser chances to re-record them.\nThere are no live sessions planned yet for this course… the absence of enough sessions (especially given that it’s a 2-credit course) will worsen the situation.\nFinally, I feel I might be able to better appreciate the technicalities and jargon if I finish all other ML courses before taking this up."
      },
      {
        "user_id": null,
        "content": "Imagine if your reason doesn’t get resolved even after all ML courses are over then in that case you will underutilize your time. So I would suggest don’t think of dropping, it is just a course and we just need to pass it and leverage this knowledge to search for better resources and learning material.\n@Anand"
      },
      {
        "user_id": null,
        "content": "CKPIITM:\nI know I can pass any course but I don’t just wanna pass without any concrete learning.\nwasn’t it you who wrote this earlier"
      },
      {
        "user_id": null,
        "content": "But this will not lead me to dropping either. I always find ways to learn.\nI start with expectation and then start my own search for knowledge."
      },
      {
        "user_id": null,
        "content": "I certainly differ from the point of view of the conversation going on in this thread.\nIn my opinion, I am thinking this first week of content as to understand how the problems or objective come from a company which needs these models to implemented. It is more of a professional view rather than a student view. We need to first understand the problem and then start the solution rather than just jumping on to modelling each question."
      },
      {
        "user_id": null,
        "content": "I also found 1st week content engaging and practical. Maybe I will get few questions wrong,but I feel the concept of discovering the problem was well introduced."
      },
      {
        "user_id": null,
        "content": "I too find content of week 1 engaging and practical. I agree with\n@anand095\nand\n@akruti\n."
      },
      {
        "user_id": null,
        "content": "Interesting!  Just this morning, during my morning walk I was thinking how each of us is different in our outlook, our potential, how we realize it, how we’re challenged…and the recent posts show that we indeed are different!  It’s important that none of us stay put on what works for us and what we think is right, but be willing to see the other point of view too…\nI think I’m starting to understand the other points of view…well I’m trying to"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/tds-p1-help-needed/179246/8",
    "posts": [
      {
        "user_id": null,
        "content": "I have uploaded exactly the files that need to be uploaded and I have set the required environment variables but I cannot get any output whatsoever. Setting the right API key, creating the correct database file- I have done all of it and yet I cannot figure out why\naren’t\nmy credits being used up (so API calling is\nnot working\n) or how to fix the error I keep getting repeatedly which is attached as follows. If anyone has completed, please help me out on this one. I have a friend who followed the exact same steps as given in a blueprint, and his one worked.\n@carlton\nsir pls help me out\nScreenshot 2025-06-14 232139\n1919×999 69.8 KB"
      },
      {
        "user_id": null,
        "content": "Can you share your yaml file also."
      },
      {
        "user_id": null,
        "content": "yeah sure- I am using the same one that was provided by S. Anand sir in the\nhttps://tds.s-anand.net/\nwebpage\nI have this one attached below\nproviders:\n  - id: https\n    config:\n      url: 'your app url'\n      method: POST\n      headers:\n        Content-Type: application/json\n      body: |\n        {\n          \"question\": \"{{ question }}\"{% if image %},\n          \"image\": \"{{ image }}\"{% endif %}\n        }\n \n        }\n      transformResponse: json\n\n# Ensure JSON schema\ndefaultTest:\n  options:\n    provider:\n      id: https\n      config:\n        url: https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\n        method: POST\n        headers:\n          Content-Type: application/json\n          Authorization: Bearer {{env.API_KEY}} # Replace with your token\n        body: |\n          {\n            \"model\": \"gpt-4o-mini\",\n            \"messages\": [\n              {\"role\": \"system\", \"content\": \"You are an evaluator that checks if an output meets specific criteria. Analyze the output based on the given rubric and respond with a JSON object containing {\\\"reason\\\": \\\"your analysis\\\", \\\"score\\\": number between 0.0 and 1.0, \\\"pass\\\": true/false}.\"},\n              {\"role\": \"user\", \"content\": \"Output to evaluate: {{ output }}\\n\\nRubric: {{ rubric }}\"}\n            ],\n            \"temperature\": 0\n          }\n        transformResponse: json\n\n  assert:\n    - type: is-json\n      value:\n        type: object\n        required: [answer, links]\n        properties:\n          answer: { type: string }\n          links:\n            type: array\n            items:\n              type: object\n              required: [url, text]\n              properties:\n                url: { type: string }\n                text: { type: string }\n\ntests:\n  - vars:\n      question: The question asks to use gpt-3.5-turbo-0125 model but the ai-proxy provided by Anand sir only supports gpt-4o-mini. So should we just use gpt-4o-mini or use the OpenAI API for gpt3.5 turbo?\n      image: file://project-tds-virtual-ta-q1.webp\n      link: https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Clarifies use of gpt-3.5-turbo-0125 not gpt-4o-mini\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939\n\n  - vars:\n      question: If a student scores 10/10 on GA4 as well as a bonus, how would it appear on the dashboard?\n      link: https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-jan-2025/165959/388\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Mentions the dashboard showing \"110\"\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-jan-2025/165959\n  - vars:\n      question: I know Docker but have not used Podman before. Should I use Docker for this course?\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Recommends Podman for the course\n      - type: llm-rubric\n        transform: output.answer\n        value: Mentions that Docker is acceptable\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://tds.s-anand.net/#/docker\n  - vars:\n      question: When is the TDS Sep 2025 end-term exam?\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Says it doesn't know (since this information is not available yet)\n\nwriteLatestResults: true\n\ncommandLineOptions:\n  cache: false"
      },
      {
        "user_id": null,
        "content": "Have you modified this yanl file by changing the url to your api endpoint?"
      },
      {
        "user_id": null,
        "content": "yes absolutely, well an update is, I got 3 successes and just 1 failure instead of 0 successes and 4 failures. turns out I was missing the word query from the url endpoint so that’s why it was unable to fetch.\nthe problem I am stuck at right now is in the screenshot shown below\nScreenshot 2025-06-15 134631\n1919×851 57.3 KB"
      },
      {
        "user_id": null,
        "content": "This is related to your embeddings or your propmt i believe.. not avle to find relevant answer. May be try changing your prompt or check the topchunks it got for this request and find whether it is getting the correct chunka nd it has the required details."
      },
      {
        "user_id": null,
        "content": "okay, got it. I will try that and see. Thank you for your help, really appreciate it."
      },
      {
        "user_id": null,
        "content": "Brother can you please help ? Actually i am using render for api hosting when ever i run this yaml file with image link i got error as render can’t process image can you please sugest a way or any new api hosting platform and also on which software you running the yaml file (i acctually using ubuntu)"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/pipe-tokens-quota-refill/179290/1",
    "posts": [
      {
        "user_id": null,
        "content": "sir i want to ask u when will the api pipe token be refreshed in 7 days after use or weekly pattern ??? please do answer\n@s.anand\n@carlton"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/ga3-large-language-models-discussion-thread-tds-may-2025/175592/231",
    "posts": [
      {
        "user_id": null,
        "content": "Error: Invalid promptfooconfig.yaml: Missing required assertion for:\nhttps://api.github.com/orgs/"
      },
      {
        "user_id": null,
        "content": "How is the structure of the llm-rubric assertion look like. I am failing that test.\n-\nname:\nllm_rubric_test\nvars:\n{}\nassert:\n-\ntype:\nllm-rubric\nvalue:\n|"
      },
      {
        "user_id": null,
        "content": "image\n1920×1200 143 KB\nHi There!\nI have submitted all the solutions on time in the TDS 2025 May GA2 on time and got a score of (9/10) but still it it showing not attempted in the graded section.\n{B67CE508-CED4-444C-BAD4-9B69D0E155A7}\n1920×1113 63.2 KB\nSimilar such case happen with me i the\nTDS 2025 May GA1\nwhere I solved all the questions correctly checked and saved them but still my score is being displayed as\n0\n.\nPlease resolve this doubt"
      },
      {
        "user_id": null,
        "content": "If you done the Question 9 for RAG could you please share the code"
      },
      {
        "user_id": null,
        "content": "{99DED93A-7530-46DD-AA65-5BF0468D6BDD}\n1920×1113 62.8 KB"
      },
      {
        "user_id": null,
        "content": "No need to worry\nTDS\nCourse uses separate server from the seek portal to store the results\nThey will get updated later in dashboard (They mentioned this in a live session)"
      },
      {
        "user_id": null,
        "content": "I have used a\ndemolab api\nwith\nopenai_api_key\nwhich credits are expired so it will not work for you because last credit was remaining which I have already used.\n[Note] : Even I am not able to solve this problem but utilised the backdoor of hackerone pentester’s injection protocol, so basically I didn’t solved this problem but cracked it.\nHere is the api :\nhttps://demolab-tdssolved.pages.dev/api/GA3/9"
      },
      {
        "user_id": null,
        "content": "How to fix this error:\nError: Invalid promptfooconfig.yaml: Your config must include at least one llm-rubric assertion.\nI have tried in 2 ways , it is some issue with the format but not sure:\n-\nname:\nllm_rubric_test\nvars:\n{}\nassert:\ntype:\nllm-rubric\nvalue:\nand\n-\nname:\nllm_rubric_test\nvars:\n{}\nassert:\n-\ntype:\nllm-rubric\nvalue:\nBoth of the above failing. which is the correct format?"
      },
      {
        "user_id": null,
        "content": "name:\nRubric\nTest\nvars:\n{}\nassert:\ntype:\nllm-rubric\nrubric:\n|\n        Enter anything\nThis thing works"
      },
      {
        "user_id": null,
        "content": "Me too…has anyone found a solution ?"
      },
      {
        "user_id": null,
        "content": "tests:\n-\nname:\n....\nvars:\n{}\nassert:\ntype:\n....\nvalue:\n...\n-\nname:\n....\nvars:\n{}\nassert:\ntype:\n.....\nvalue:\n.....\nUse something like this will work"
      },
      {
        "user_id": null,
        "content": "You can see on website there is recent saves,\nthe last recent save before the deadline\nwill be considered as your final marks in that weekly assignment."
      },
      {
        "user_id": null,
        "content": "GA3 - Large Language Models - Discussion Thread [TDS May 2025]\nTools in Data Science\ntests:\n  - name: ....\n    vars: {}\n    assert:\n      type: ....\n      value: ...\n\n  - name: ....\n    vars: {}\n    assert:\n      type: .....\n      value: .....\n\nUse something like this will work\nRefer this post"
      },
      {
        "user_id": null,
        "content": "GA3 - Large Language Models - Discussion Thread [TDS May 2025]\nTools in Data Science\ntests:\n  - name: ....\n    vars: {}\n    assert:\n      type: ....\n      value: ...\n\n  - name: ....\n    vars: {}\n    assert:\n      type: .....\n      value: .....\n\nUse something like this will work\nRefer this post"
      },
      {
        "user_id": null,
        "content": "For Questions 8 to 10 of GA3 (Tools in Data Science), which involve working with LLMs and APIs, how and where should we host the URL to receive and handle the responses effectively?"
      },
      {
        "user_id": null,
        "content": "You can start the servers locally on different ports, or you can host the api on any platform like vercel, netlify, GCP, AWS, DO etc"
      },
      {
        "user_id": null,
        "content": "Screenshot (1110)\n1920×1200 134 KB\nHere it is what will be my score and Why it is not being displayed on my dashboard.\nAssignment is marked as\nnot attempted\nin the grades section of the course."
      },
      {
        "user_id": null,
        "content": "@carlton\n@Jivraj\nsir please provide complete detailed solution of q9"
      },
      {
        "user_id": null,
        "content": "guys you all can check my repos i have made git repos of some imp questions with my solutions\nGitHub\nsaumyakumarchauhan - Overview\nStudent at IIT Madras and IIIT Kota\n. saumyakumarchauhan has 11 repositories available. Follow their code on GitHub."
      },
      {
        "user_id": null,
        "content": "bro is you issue resolve or not tell me some thing i also get same issue"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-may-2025/178881/3",
    "posts": [
      {
        "user_id": null,
        "content": "Please post any questions related to\nGraded Assignment 4 - Data Sourcing\n.\nDeadline:\nSunday, June 22, 2025 11:59 PM\n@carlton\n@Jivraj\n@HritikRoshan_HRM"
      },
      {
        "user_id": null,
        "content": "Subject:\nIssue with Scraping BBC Weather API for Nur-Sultan JSON Forecast\nQuestion 4: Scraping BBC Weather API for Nur-Sultan Weather Forecast\nI’m trying to retrieve the JSON weather forecast description for Nur-Sultan using the BBC Weather API. However, I noticed that the BBC website lists the city as “Astana” instead of Nur-Sultan. When I attempt to use the JSON data for Astana, I encounter the following error:\nTypeError: Cannot read properties of undefined (reading ‘id’)\nHow should I proceed to correctly scrape the weather forecast for Nur-Sultan?  how can I resolve the TypeError issue? Any guidance on handling city name"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/iitm-github-account-flagged/179311/1",
    "posts": [
      {
        "user_id": null,
        "content": "My IITM GitHub account is flagged and I am not able to deploy my TDS project 1 on third-party applications, kindly help me out with this, thank you\nScreenshot (1225)\n1920×1080 273 KB"
      },
      {
        "user_id": null,
        "content": "Shall I deploy the project using my personal Github account, please clarify this\n@s.anand\nSir and\n@carlton\nSir!!"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/tds-project-1-2025/179103",
    "posts": [
      {
        "user_id": null,
        "content": "I’ve watched the YouTube sessions for Project 1, but I’m feeling quite confused. I’ve managed to scrape data from Discourse, and the content is now saved in multiple files. I’ve converted these files into\n.md\n(Markdown) format, but I’m having trouble handling the images — I’m not able to extract or display them properly.   Can anyone help?"
      },
      {
        "user_id": null,
        "content": "Can you please clarify how you scraped the data . I am not able to do it. Please Help me."
      },
      {
        "user_id": null,
        "content": "You can watch project sessions of tds in youtube playlist. They have mentioned and shown example of how to scrape the data."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/npx-y-promptfoo-eval-config-project-tds-virtual-ta-promptfoo-yaml-error/179170/2",
    "posts": [
      {
        "user_id": null,
        "content": "npx -y promptfoo eval --config project-tds-virtual-ta-promptfoo.yaml\ni am getting the following error \n expected output to contain \"https://discourse.online...\ncould you pls tell what changes should i make to my api code. thanks\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom typing import Optional, List\nimport json\nfrom fastapi.responses import JSONResponse\n\n# Load data from JSON file\nwith open(\"discourse_posts.json\", \"r\") as f:\n    discourse_posts = json.load(f)\n\napp = FastAPI()\n\n# Define request/response models\nclass QuestionRequest(BaseModel):\n    question: str\n    image: Optional[str] = None\n\nclass Link(BaseModel):\n    url: str\n    text: str\n\nclass AnswerResponse(BaseModel):\n    answer: str\n    links: List[Link]\n    url: str\n    topic_title: str\n\n@app.post(\"/api\", response_model=AnswerResponse)\nasync def get_answer(request: QuestionRequest):\n    print(\"Received question:\", request.question)\n    question = request.question\n    for post in discourse_posts:\n        if any(word.lower() in question.lower() for word in post[\"question_keywords\"]):\n            return AnswerResponse(\n                answer=post[\"answer\"],\n                links=[Link(**link) for link in post[\"links\"]],\n                url=post[\"url\"],\n                topic_title=post[\"topic_title\"]\n            )\n\n    # Default fallback response with required fields\n    return AnswerResponse(\n        answer=\"Sorry, I couldn't find an answer to your question.\",\n        links=[],\n        url=\"https://tds.s-anand.net/#/\",\n        topic_title=\"Unknown topic\"\n    )\n\n@app.get(\"/\")\nasync def read_root():\n    return {\"message\": \"TDS API server is running.\"}\n\n@app.get(\"/favicon.ico\")\nasync def favicon():\n    return {}\n\n\npls help @jivraj @hrithik"
      },
      {
        "user_id": null,
        "content": "@Jivraj\n@HritikRoshan_HRM"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/hello-i-need-some-help/179142",
    "posts": [
      {
        "user_id": null,
        "content": "I want some help in tds project"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939",
    "posts": [
      {
        "user_id": null,
        "content": "image\n756×295 19.5 KB\nThe question asks to use gpt-3.5-turbo-0125 model but the ai-proxy provided by Anand sir only supports gpt-4o-mini. So should we just use gpt-4o-mini or use the OpenAI API for gpt3.5 turbo?\n@carlton"
      },
      {
        "user_id": null,
        "content": "I tried gpt-3.5-turbo-0125 with python’s tiktoken library , I got a different value for prompt token compared gpt-4o-mini from the proxy api."
      },
      {
        "user_id": null,
        "content": "My understanding is that you just have to use a tokenizer, similar to what Prof. Anand used, to get the number of tokens and multiply that by the given rate."
      },
      {
        "user_id": null,
        "content": "Use the model that’s mentioned in the question."
      },
      {
        "user_id": null,
        "content": "The answer should be 0.00165 right."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/hello-i-need-some-help/179142/1",
    "posts": [
      {
        "user_id": null,
        "content": "I want some help in tds project"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/tds-p1-help-needed/179246",
    "posts": [
      {
        "user_id": null,
        "content": "I have uploaded exactly the files that need to be uploaded and I have set the required environment variables but I cannot get any output whatsoever. Setting the right API key, creating the correct database file- I have done all of it and yet I cannot figure out why\naren’t\nmy credits being used up (so API calling is\nnot working\n) or how to fix the error I keep getting repeatedly which is attached as follows. If anyone has completed, please help me out on this one. I have a friend who followed the exact same steps as given in a blueprint, and his one worked.\n@carlton\nsir pls help me out\nScreenshot 2025-06-14 232139\n1919×999 69.8 KB"
      },
      {
        "user_id": null,
        "content": "Can you share your yaml file also."
      },
      {
        "user_id": null,
        "content": "yeah sure- I am using the same one that was provided by S. Anand sir in the\nhttps://tds.s-anand.net/\nwebpage\nI have this one attached below\nproviders:\n  - id: https\n    config:\n      url: 'your app url'\n      method: POST\n      headers:\n        Content-Type: application/json\n      body: |\n        {\n          \"question\": \"{{ question }}\"{% if image %},\n          \"image\": \"{{ image }}\"{% endif %}\n        }\n \n        }\n      transformResponse: json\n\n# Ensure JSON schema\ndefaultTest:\n  options:\n    provider:\n      id: https\n      config:\n        url: https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\n        method: POST\n        headers:\n          Content-Type: application/json\n          Authorization: Bearer {{env.API_KEY}} # Replace with your token\n        body: |\n          {\n            \"model\": \"gpt-4o-mini\",\n            \"messages\": [\n              {\"role\": \"system\", \"content\": \"You are an evaluator that checks if an output meets specific criteria. Analyze the output based on the given rubric and respond with a JSON object containing {\\\"reason\\\": \\\"your analysis\\\", \\\"score\\\": number between 0.0 and 1.0, \\\"pass\\\": true/false}.\"},\n              {\"role\": \"user\", \"content\": \"Output to evaluate: {{ output }}\\n\\nRubric: {{ rubric }}\"}\n            ],\n            \"temperature\": 0\n          }\n        transformResponse: json\n\n  assert:\n    - type: is-json\n      value:\n        type: object\n        required: [answer, links]\n        properties:\n          answer: { type: string }\n          links:\n            type: array\n            items:\n              type: object\n              required: [url, text]\n              properties:\n                url: { type: string }\n                text: { type: string }\n\ntests:\n  - vars:\n      question: The question asks to use gpt-3.5-turbo-0125 model but the ai-proxy provided by Anand sir only supports gpt-4o-mini. So should we just use gpt-4o-mini or use the OpenAI API for gpt3.5 turbo?\n      image: file://project-tds-virtual-ta-q1.webp\n      link: https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Clarifies use of gpt-3.5-turbo-0125 not gpt-4o-mini\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939\n\n  - vars:\n      question: If a student scores 10/10 on GA4 as well as a bonus, how would it appear on the dashboard?\n      link: https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-jan-2025/165959/388\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Mentions the dashboard showing \"110\"\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-jan-2025/165959\n  - vars:\n      question: I know Docker but have not used Podman before. Should I use Docker for this course?\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Recommends Podman for the course\n      - type: llm-rubric\n        transform: output.answer\n        value: Mentions that Docker is acceptable\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://tds.s-anand.net/#/docker\n  - vars:\n      question: When is the TDS Sep 2025 end-term exam?\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Says it doesn't know (since this information is not available yet)\n\nwriteLatestResults: true\n\ncommandLineOptions:\n  cache: false"
      },
      {
        "user_id": null,
        "content": "Have you modified this yanl file by changing the url to your api endpoint?"
      },
      {
        "user_id": null,
        "content": "yes absolutely, well an update is, I got 3 successes and just 1 failure instead of 0 successes and 4 failures. turns out I was missing the word query from the url endpoint so that’s why it was unable to fetch.\nthe problem I am stuck at right now is in the screenshot shown below\nScreenshot 2025-06-15 134631\n1919×851 57.3 KB"
      },
      {
        "user_id": null,
        "content": "This is related to your embeddings or your propmt i believe.. not avle to find relevant answer. May be try changing your prompt or check the topchunks it got for this request and find whether it is getting the correct chunka nd it has the required details."
      },
      {
        "user_id": null,
        "content": "okay, got it. I will try that and see. Thank you for your help, really appreciate it."
      },
      {
        "user_id": null,
        "content": "Brother can you please help ? Actually i am using render for api hosting when ever i run this yaml file with image link i got error as render can’t process image can you please sugest a way or any new api hosting platform and also on which software you running the yaml file (i acctually using ubuntu)"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/project1-virtual-ta-discussion-thread-tds-may-2025/176077/1",
    "posts": [
      {
        "user_id": null,
        "content": "Please post any questions related to\nProject 1\nPlease use markdown code formatting (fenced code blocks beginning with ```) when sharing code (rather than screenshots). It’s easier for us to copy-paste and test.\nDeadline:\nJune 14, 2025 11:59 PM\nDeadline:\nTomorrow 11:59 PM"
      },
      {
        "user_id": null,
        "content": "@s.anand\n@carlton\nSir i am done with my api endpoint for project 1 but i did one change in the given test file where we have to edit our api endpoint and test it as mentioned in the project description. I was testing my model but was getting the same response every time even though my model was giving the expected answer to those question when tested separately. I found that in the test file (promptfoo.yaml) the cache is marked as true and because of which whenever i try to run the test file it does not hit my api endpoint and take the old response from the cache. So i changed the cache to false and tried running that test file and got the results as shown below in the image.\nimage\n1861×912 105 KB\nIn this as you can see for the 2nd test case since i am using the openai model to give the final answer so it is using my context and saying that dashboard will show 11/10, but the expected answer should contain “110”. The problem i am facing is as you can see the url given in my response is same as expected which means my model is picking the right context to answer the question but since i am using openai to make my final answer using this context it is very unlikely that it will say that dashboard will show “110” because this doesn’t make sense. So can you please help me how should i tackle this ? As this is the only test case left.\nAnd also i have added one prompt field in the test file because i was getting warning regarding this missing field again and again. So is it okay ?"
      },
      {
        "user_id": null,
        "content": "@HritikRoshan_HRM\nsir can you please help me with this."
      },
      {
        "user_id": null,
        "content": "Not able to access the tds project link.\nTDS_Project1\n898×509 16.7 KB"
      },
      {
        "user_id": null,
        "content": "tds.s-anand.net\nTools in Data Science"
      },
      {
        "user_id": null,
        "content": "Not this one the GitHub repository URL and API endpoint URL submission link not opening.\nSir my all links are working like I submitted by GA1 also but only my project submission link not working. Please solve the problem. How will I submit my project?"
      },
      {
        "user_id": null,
        "content": "Have you completed your project ? I have some doubts."
      },
      {
        "user_id": null,
        "content": "not yet but how will I gonna submit it. I can’t post this at end. My link should be working to submit my project before deadline."
      },
      {
        "user_id": null,
        "content": "Submission date is next month, maybe by then they will fix it. I am also not able access submission link."
      },
      {
        "user_id": null,
        "content": "Sir, the question’s background specifies that we should use Discourse posts from\nJanuary 1, 2025 through April 14, 2025\n. However, in\nfirst testcase\nwe are asked to answer based on the following Discourse post—which dates outside that window:\nhttps://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939\nIs this an error in the question’s timeframe?"
      },
      {
        "user_id": null,
        "content": "Interesting, that’s my post from Sep 24 Term. I am curious about the context and why did an 8 month old post come up in a Test."
      },
      {
        "user_id": null,
        "content": "I guess, this question is also covered in previous term, i.e., t1-2025"
      },
      {
        "user_id": null,
        "content": "Actually, in this term (May 25), we received our first project as\nTDS Virtual TA\n, where we are tasked with designing a chatbot API that acts as a virtual TA. For this project, your post has been provided as an example test case."
      },
      {
        "user_id": null,
        "content": "Sorry, but I couldn’t find any related question. Could you please send me the link to the post, if you have it?"
      },
      {
        "user_id": null,
        "content": "It maybe in week-4 or 5 GA"
      },
      {
        "user_id": null,
        "content": "@Jivraj\n@carlton\nSir, any updates on my issue?"
      },
      {
        "user_id": null,
        "content": "Sir, i have build an initial model for my project and when i test some question separately then i get somewhat expected answer like\nimage\n1136×435 11.3 KB\nthis is the response which i got from my model\n@carlton\nsir can you please help me in this"
      },
      {
        "user_id": null,
        "content": "And the in the test file given in the project description this is the response for this question\nimage\n965×296 9.81 KB"
      },
      {
        "user_id": null,
        "content": "This is the response of the same question given in the promtfoo.yaml file which we have to use for the testing purpose by editing our api endpoint.\nBut the issue is, when i test this file by running that promtfoo.yaml file by editing my api endpoin then for this same question the test case fails.\nimage\n1179×191 12.9 KB\nalso the answer which it shows is not what i get when i run my model for this question as shown in the above image. Can you please help me with this, where i am going wrong ?"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/project1-virtual-ta-discussion-thread-tds-may-2025/176077/243",
    "posts": [
      {
        "user_id": null,
        "content": "Hi\n@Karvy\nImage can be any type of image that are on discourse.\nThere is way to handle images for processing(resizing, etc) via identifying mime-type from file headers that come through post request.\nTo identify the\nMIME type\nof the image sent in the request, you need to:\nStep 1: Decode the base64 string\nThe incoming\nimage\nfield in the request JSON is a\nbase64-encoded image\n, like this:\n\"image\"\n:\n\"data of base64...\"\nOn the server side (e.g., in Python), you’ll first\ndecode the base64 string\n.\nStep 2: Inspect the raw bytes to get MIME type\nThere are a few ways to do this depending on your server stack. Below is a method using\nPython\n:\nPython Code Example (for FastAPI, Flask, Django etc.)\nimport\nbase64\nimport\nimghdr\nimport\nmimetypes\nfrom\nio\nimport\nBytesIO\ndef\nget_image_mimetype\n(\nbase64_string\n):\n# Decode base64 string\nimage_data = base64.b64decode(base64_string)\n# Option 1: imghdr (basic)\nimg_type = imghdr.what(\nNone\n, h=image_data)\n# e.g., 'jpeg', 'png', 'webp'\nmime_type =\nf'image/\n{img_type}\n'\nif\nimg_type\nelse\n'application/octet-stream'\nreturn\nmime_type\nExample Output\nIf the image is WebP, it will return:\nimage/webp"
      },
      {
        "user_id": null,
        "content": "what do you mean by your-openai-api-url.\nOPENAI_API_BASE=https://your-openai-api-url/v1\ni am using it as:\nllm_model = ChatOpenAI(\n        model=\n\"gpt-4o-mini\"\n,\n        openai_api_key=AIPIPE_TOKEN,\n        openai_api_base=\n\"https://aiproxy.sanand.workers.dev/openai/v1\"\n)"
      },
      {
        "user_id": null,
        "content": "Hi any updates on this? Or can we just increase our timeframe to get more posts in"
      },
      {
        "user_id": null,
        "content": "WhatsApp Image 2025-06-12 at 00.20.42_2104b0eb\n1280×589 164 KB\nimage\n1435×655 60.9 KB\nplease help me is there any issue in scrapping or in my"
      },
      {
        "user_id": null,
        "content": "image\n1201×727 64.2 KB\nplease\n@carlton\nand\n@Jivraj\nsir help me i am getting 1 test case fail of expected url but i am confused that i am doing mistake in code or scrapping is done wrong? how do i resolve it please guide me"
      },
      {
        "user_id": null,
        "content": "yes for testing locally on your server you have to keep that image in your folder"
      },
      {
        "user_id": null,
        "content": "Yes, promptfoo does an exact url matching as told by Jivrag in an earlier post.\nFor the discourse posts you can also build the url by providing the base url and the slug and post number while replying if your data does not have the link.\nFor the third test case i cannot see the links related to the course content. So please check if you have those links in your data. If yes then try some more chunks like top 10 chunks to see if your model is able to pick that. In the course content page every page have its link that link we have to provide in the answer if the question is related to the content of that page."
      },
      {
        "user_id": null,
        "content": "@carlton\n@Jivraj\nSir, I am having submitting my project’s  public url,\nimage\n2612×636 62.7 KB\nBut when tested with url via postman, I am getting results but on the portal it is saying failed to fetch.\nKindly help me to fix this,\nThank you"
      },
      {
        "user_id": null,
        "content": "Hi\n@Jivraj\n@carlton\n,\nIn yesterday’s session, we talked about preparing data which involved conversion of html code to markdown and describing images within the code using Google Gemini API.\nimage\n699×124 28.3 KB\nQuery/Concern:\nAs per my sourced data from Discourse API, I have 120 topic threads (in the provided date range), each having some posts, where some posts will contain some images.\nI converted one of the topic Json files into the corresponding markdown file and added image descriptions. It took me more than a minute. So 120 would mean around 2hrs or so. Is this expected?\nThe Gemini model “Gemini 2.0 Flask”  has a limitation to its free tier: 15 requests in 1 minute. Will this create a problem? If yes, any suggestion on handling this?\nEdit: I have added a delay of 4 seconds after every call to Google Gemini API.\nI also noticed that the emojis are being treated as images in the markdown. Maybe I can add a filter to skip those, but just wanted to confirm if I am on the right track when it comes to preparing data.\nThanks."
      },
      {
        "user_id": null,
        "content": "Hi\n@carlton\n,\nMy model is working properly but in one question given in rubrics\nAbout bonus marks , how they appear on dashboard\nModel sometimes include 110 sometime just say 11/10\nSo how shall i overcome this issue, can you help me\nThanks"
      },
      {
        "user_id": null,
        "content": "Have you added CORS? i think that will solve the issue"
      },
      {
        "user_id": null,
        "content": "image\n1855×669 69.8 KB\nimage\n1893×820 81.1 KB\nnow i have done exactly what you said now the problem is it is still not giving me that links which is said to be appropriate now what should i do and i was using gpt-4.1-nano and model = SentenceTransformer(“all-MiniLM-L6-v2”) should i change this to get better response please suggest!!"
      },
      {
        "user_id": null,
        "content": "In the third question you can see that even the top 10 chunks have all the chunks related to the discourse content only and not any link form the course content pages.\nSo make sure you have processed the course content data properly and you also have those links in your dataset. Because i don’t know how other have done this, but my approach was to keep the respective source link with all the chunks so that while answering i can give the respective link as well.\nSo whatever is your approach and pipeline, first make sure that the course content data is there and getting embedded so that your model can pick those chunks based on similarity or any other retrieval logic you are using.\nFor the first question, the question is out of the specified date range so even if it does not pass no worries."
      },
      {
        "user_id": null,
        "content": "@Jivraj\n@carlton\nsir will there be any extension provided? Please consider that most of us are completely new and are trying to do this project from scratch. The project sessions have just started and the deadline is already hanging over our heads, not to forget we’d paradox also and we also have other subjects and projects. It’s a humble request to please consider, extending the deadline by atleast a few days so that we can complete it well enough."
      },
      {
        "user_id": null,
        "content": "Screenshot 2025-06-12 141858\n287×369 3.67 KB\n@Jivraj\n@carlton\nThis is my final TDS Virtual TA repository on GitHub. Is it complete as per the requirements, or do I need to add anything more? Please guide me."
      },
      {
        "user_id": null,
        "content": "23f1002231:\nIn the third question you can see that even the top 10 chunks have all the chunks related to the discourse content only and not any link form the course content pages.\nSo make sure you have processed the course content data properly and you also have those links in your dataset. Because i don’t know how other have done this, but my approach was to keep the respective source link with all the chunks so that while answering i can give the respective link as well.\nSo whatever is your approach and pipeline, first make sure that the course content data is there and getting embedded so that your model can pick those chunks based on similarity or any other retrieval logic you are using.\nFor the first question, the question is out of the specified date range so even if it does not pass no worries.\nsee in 1st and 3rd even it is not mentioning the required link but it is providing other relevent link and based on it it is giving very good answer then why we need that url i dont understand it should not include in the test case. Whats your opinion on that?"
      },
      {
        "user_id": null,
        "content": "It is how promptfoo works, you need to give the exact link of the post or the course content page which answer the question. As they are thinking to make this an official QnA help for this course so providing correct and exact links is necessary otherwise they have to search for the posts.\nI have one suggestion for evaluation\n@carlton\n@Jivraj\nif our projects can be evaluated based on the assertions passed then it will be very helpful considering this is the first time many people are making this kind of project. Because for a particular test case even if one assertion failed then we will get 0 for that test case. This can impact the total project score heavily.\nAgain it is just a suggestion. But it would be very helpful if you consider this as the difficulty of this course is also increased, so this way our hard work will fetch us some marks this way."
      },
      {
        "user_id": null,
        "content": "saumya1:\nthen its very hard because they will use their test cases for the evaluation so it would be very difficult to get responses url according to them\nthen its very hard because they will use their test cases for the evaluation so it would be very difficult to get responses url according to them"
      },
      {
        "user_id": null,
        "content": "They are not using any random link its the link of the post which answered that question correctly. And if you scrape the data correctly then all the link will be in the required structure which they want.\nYes but still if they evaluate based on the assertions passed then it will be very helpful."
      },
      {
        "user_id": null,
        "content": "ohk thankyou so much"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/iitm-github-account-flagged/179311",
    "posts": [
      {
        "user_id": null,
        "content": "My IITM GitHub account is flagged and I am not able to deploy my TDS project 1 on third-party applications, kindly help me out with this, thank you\nScreenshot (1225)\n1920×1080 273 KB"
      },
      {
        "user_id": null,
        "content": "Shall I deploy the project using my personal Github account, please clarify this\n@s.anand\nSir and\n@carlton\nSir!!"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/ga3-large-language-models-discussion-thread-tds-may-2025/175592/1",
    "posts": [
      {
        "user_id": null,
        "content": "Please post any questions related to\nGraded Assignment 3 - Development Tools\n.\nPlease use markdown code formatting (fenced code blocks beginning with ```) when sharing code (rather than screenshots). It’s easier for us to copy-paste and test.\nDeadline:\nJune 1, 2025\n@Jivraj\n@Saransh_Saini\n@HritikRoshan_HRM\n@21f3002441\n@iamprasna\n@carlton"
      },
      {
        "user_id": null,
        "content": "Sir in the 9th question when entering this command\nllm embed-multi typescript-book\n--model\n3\n-small\n--store\n--format\nnl chunks\n.json\nI’m facing this problem\n2025-05-21_17h45_37\n353×185 25.6 KB\n@23f3000511"
      },
      {
        "user_id": null,
        "content": "@carlton\n@Jivraj\nis there anything wrong with Q9 of GA-3 ? I am trying for last two days but getting this as the error.\nScreenshot 2025-05-22 at 4.27.59 PM\n2938×1300 324 KB\ncould u please help me out."
      },
      {
        "user_id": null,
        "content": "Hi Asit,\nI have solved all questions of GA3 without any issues, there should not be any issues."
      },
      {
        "user_id": null,
        "content": "GA3 submission date\npreponed\nfrom 01 Jun to 25 May 2025 since there’s a break the week after\nWhich One is the real dead Line - 01 June Or 25  May 2025"
      },
      {
        "user_id": null,
        "content": "The Above Comment is written on\nTools in Data Science\nWhich was last updated on 5th of may, but it is still up there"
      },
      {
        "user_id": null,
        "content": "deadline for GA3 is 1st june"
      },
      {
        "user_id": null,
        "content": "You would need to install llm cli for using it.\nFind documentation below\nsimonw/llm: Access large language models from the command-line"
      },
      {
        "user_id": null,
        "content": "I want to confirm what is deadline of week 3 in TDS because on portal, Graded assignment of week 3 is not updated but by using URL of GA2 and by replacing 2 with 3 in URL, I can get week 3 GAs, but in docs, provided by TDS portal through Email have deadline on 25 June for GA3 but with the URL, We are getting 25 May as deadline. So please clarify this what is deadline for GA 3\nScreenshot 2025-05-19 223148\n809×321 15.6 KB\nScreenshot 2025-05-19 223532\n1617×1026 108 KB"
      },
      {
        "user_id": null,
        "content": "sir i am facing issue in every assignment where api key is needed i have exceeded my quota so it is not accepting api key in any of my account even i use my friend’s api key it shows that you have exceed your quota. Please give me solution for this last time i missed my assignment due to this problem.\nimage\n612×288 10.4 KB"
      },
      {
        "user_id": null,
        "content": "please help me\n@carlton\n@Jivraj"
      },
      {
        "user_id": null,
        "content": "OpenAi free trial credits have been discontinued?\nYes, the free credits have been discontinued earlier this year. OpenAI now for most users operates under pre-paid billing. In order to use the API you need to fund your account with a minimum balance of USD 5. Let us know if you have any further questions.\ncheck\nIs OpenAi free trial credits have been discontinued? - API - OpenAI Developer Community\nplease allow us to use different model like of deepseek or somthing else otherwise it is not possible for us to do the assignment even after using OPEN_API_KEY of any account it shows “your quota has been exceeded”"
      },
      {
        "user_id": null,
        "content": "This is most likely because you are not using the documented api endpoints. It was explained in earlier live sessions that we provide you with a key with sufficient credit to complete your assignments. But the mechanism we employ is to use a proxy. Please carefully follow the instructions in the session or on the aipipe documentation that is available on module 3 first page."
      },
      {
        "user_id": null,
        "content": "Sir which API Key to use for question 9 for running this llm\nimage\n1271×770 63.8 KB"
      },
      {
        "user_id": null,
        "content": "Admin@DESKTOP-JSC3TUA MINGW64 /f/IITM/tools_in_data_science/assignment3/Q-9/app\n$ uv run addnotes.py\nCreate collection response: 400 {“message”: “OpenAI API error: Your authentication token is not from a valid issuer.”}\nFailed to create collection. Exiting.\ni am getting this even after using AIPIPE_TOKEN every time"
      },
      {
        "user_id": null,
        "content": "Even if you use the Ai pipe token, if you do not use the right endpoints you will still get that error. Because open ai does not recognise aipipe tokens as legitimate."
      },
      {
        "user_id": null,
        "content": "i keep getting this error for Q8\nScreenshot 2025-05-25 165409\n745×529 28.1 KB"
      },
      {
        "user_id": null,
        "content": "so sir what’s the solution?"
      },
      {
        "user_id": null,
        "content": "what is the final date for submitting GA3 .. test showing 1st June.. kindly confirm\nimage\n2897×1241 283 KB"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/getting-an-api-key-error-upon-running-npx-y-promptfoo-eval-config-project-tds-virtual-ta-promptfoo-yaml/178878/2",
    "posts": [
      {
        "user_id": null,
        "content": "[FAIL] API error: 401  Unauthorized  {“error”:{“message”:\"Inc… API key provided: sk-proj-*************** You can find your API key at\nhttps://platform.openai\n.…"
      },
      {
        "user_id": null,
        "content": "@HritikRoshan_HRM\nsir\n@carlton\nsir could you pls help"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/npx-y-promptfoo-eval-config-project-tds-virtual-ta-promptfoo-yaml-error/179170/1",
    "posts": [
      {
        "user_id": null,
        "content": "npx -y promptfoo eval --config project-tds-virtual-ta-promptfoo.yaml\ni am getting the following error \n expected output to contain \"https://discourse.online...\ncould you pls tell what changes should i make to my api code. thanks\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom typing import Optional, List\nimport json\nfrom fastapi.responses import JSONResponse\n\n# Load data from JSON file\nwith open(\"discourse_posts.json\", \"r\") as f:\n    discourse_posts = json.load(f)\n\napp = FastAPI()\n\n# Define request/response models\nclass QuestionRequest(BaseModel):\n    question: str\n    image: Optional[str] = None\n\nclass Link(BaseModel):\n    url: str\n    text: str\n\nclass AnswerResponse(BaseModel):\n    answer: str\n    links: List[Link]\n    url: str\n    topic_title: str\n\n@app.post(\"/api\", response_model=AnswerResponse)\nasync def get_answer(request: QuestionRequest):\n    print(\"Received question:\", request.question)\n    question = request.question\n    for post in discourse_posts:\n        if any(word.lower() in question.lower() for word in post[\"question_keywords\"]):\n            return AnswerResponse(\n                answer=post[\"answer\"],\n                links=[Link(**link) for link in post[\"links\"]],\n                url=post[\"url\"],\n                topic_title=post[\"topic_title\"]\n            )\n\n    # Default fallback response with required fields\n    return AnswerResponse(\n        answer=\"Sorry, I couldn't find an answer to your question.\",\n        links=[],\n        url=\"https://tds.s-anand.net/#/\",\n        topic_title=\"Unknown topic\"\n    )\n\n@app.get(\"/\")\nasync def read_root():\n    return {\"message\": \"TDS API server is running.\"}\n\n@app.get(\"/favicon.ico\")\nasync def favicon():\n    return {}\n\n\npls help @jivraj @hrithik"
      },
      {
        "user_id": null,
        "content": "@Jivraj\n@HritikRoshan_HRM"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/a-humble-request-to-the-tds-course-team/179034/7",
    "posts": [
      {
        "user_id": null,
        "content": "@carlton\nand\n@Jivraj\nRespected Sir\nIt was my first time doing web scraping and other tasks required for this project. After watching the live sessions, I realized that my approach was wrong. The live sessions are really good\nbut\n, they are being conducted too close to the deadline (started on 10th June). In the sessions, it was said that this project could be completed in a day, but I don’t feel that this is the case for me (not even close), though that might just be my own inefficiency.\nAside from that, the method of using the Gemini model demonstrated in the sessions only allowed me to generate embeddings for the first 100 chunks (max per day), there are way more than that in my workflow. I have to spend time finding other alternatives to create embeddings before I make the final submission with the openAI api. So, I humbly request, if it is possible, please consider extending the deadline by a few days. There is not enough time to absorb what was taught in the live sessions and implement it as complete beginner.\nThank you."
      },
      {
        "user_id": null,
        "content": "23f1000917:\nAside from that, the method of using the Gemini model demonstrated in the sessions only allowed me to generate embeddings for the first 100 chunks (max per day), there are way more than that in my workflow. I have to spend time finding other alternatives to create embeddings before I make the final submission with the openAI api. So, I humbly request, if it is possible, please consider extending the deadline by a few days. There is not enough time to absorb what was taught in the live sessions and implement it as complete beginner.\nit will be helpful if deadline extended by 2-3 days"
      },
      {
        "user_id": null,
        "content": "Yes sir please extend the deadline"
      },
      {
        "user_id": null,
        "content": "please extend the deadline"
      },
      {
        "user_id": null,
        "content": "please extend the deadline"
      },
      {
        "user_id": null,
        "content": "Already extended till 18th.\nOn another topic\nPlease post any questions related to\nProject 1\nPlease use markdown code formatting (fenced code blocks beginning with ```) when sharing code (rather than screenshots). It’s easier for us to copy-paste and test.\nDeadline:\nJune 14, 2025 11:59 PM\nDeadline:\nTomorrow 11:59 PM"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/submissions-of-weekly-graded-assignment-of-tds/178618/3",
    "posts": [
      {
        "user_id": null,
        "content": "@Jivraj\n@21f3002441\nI have submitted the weekly graded assignments for Tools in Data science, from the correct google account and yet it has been showing not submitted from the past three weeks. Could you help me with this?\ncomplaint1\n900×874 122 KB\n, this is shown and yet it is showing not submitted in the grades section\nsimilar problem for all three weeks. Please let me know"
      },
      {
        "user_id": null,
        "content": "Hi\n@24f1002463\nWhat do you see on course page ?\nNptel Seekh"
      },
      {
        "user_id": null,
        "content": "Thank you. There seems to be a glitch, because now, marks are visible on the course page but when I check grades individually for the course, it still says not submitted."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/a-humble-request-to-the-tds-course-team/179034",
    "posts": [
      {
        "user_id": null,
        "content": "@carlton\nand\n@Jivraj\nRespected Sir\nIt was my first time doing web scraping and other tasks required for this project. After watching the live sessions, I realized that my approach was wrong. The live sessions are really good\nbut\n, they are being conducted too close to the deadline (started on 10th June). In the sessions, it was said that this project could be completed in a day, but I don’t feel that this is the case for me (not even close), though that might just be my own inefficiency.\nAside from that, the method of using the Gemini model demonstrated in the sessions only allowed me to generate embeddings for the first 100 chunks (max per day), there are way more than that in my workflow. I have to spend time finding other alternatives to create embeddings before I make the final submission with the openAI api. So, I humbly request, if it is possible, please consider extending the deadline by a few days. There is not enough time to absorb what was taught in the live sessions and implement it as complete beginner.\nThank you."
      },
      {
        "user_id": null,
        "content": "23f1000917:\nAside from that, the method of using the Gemini model demonstrated in the sessions only allowed me to generate embeddings for the first 100 chunks (max per day), there are way more than that in my workflow. I have to spend time finding other alternatives to create embeddings before I make the final submission with the openAI api. So, I humbly request, if it is possible, please consider extending the deadline by a few days. There is not enough time to absorb what was taught in the live sessions and implement it as complete beginner.\nit will be helpful if deadline extended by 2-3 days"
      },
      {
        "user_id": null,
        "content": "Yes sir please extend the deadline"
      },
      {
        "user_id": null,
        "content": "please extend the deadline"
      },
      {
        "user_id": null,
        "content": "please extend the deadline"
      },
      {
        "user_id": null,
        "content": "Already extended till 18th.\nOn another topic\nPlease post any questions related to\nProject 1\nPlease use markdown code formatting (fenced code blocks beginning with ```) when sharing code (rather than screenshots). It’s easier for us to copy-paste and test.\nDeadline:\nJune 14, 2025 11:59 PM\nDeadline:\nTomorrow 11:59 PM"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/github-account-made-using-the-iitm-email-id-keeps-getting-blocked/179166/1",
    "posts": [
      {
        "user_id": null,
        "content": "Hello everyone,\nI have earlier submitted the project1 successfully and saved it to. Today i just wanted to verify if my submissions were still working as the project said (The URL should be accessible when the project team evaluates your submission.)\nThe API endpoint which i depolyed on Render is still working just fine\n(takes a little while when tested after a while for the application to start)\nbut the github repo which i used to deploy the project is not accesibible\nThis is second time my github account got blocked.\nAnd i am also unable to unblock it today as i have already surpassed the sms otp limit for the day (it was going to spam\n)\nPlease let me know if i will be scored fairly"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/pipe-tokens-quota-refill/179290",
    "posts": [
      {
        "user_id": null,
        "content": "sir i want to ask u when will the api pipe token be refreshed in 7 days after use or weekly pattern ??? please do answer\n@s.anand\n@carlton"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/api-key-error/178898/2",
    "posts": [
      {
        "user_id": null,
        "content": "(venv) C:\\Users\\User\\Desktop\\TDS Folder>python scrape/embed_documents.py\nEmbedding documents: 0it [00:00, ?it/s]\nError getting embedding: Error code: 401 - {‘error’: {‘message’: ‘Your authentication token is\nnot from a valid issuer.’, ‘type’: ‘invalid_request_error’, ‘param’: None, ‘code’: ‘invalid_issuer’}}\nEmbedding documents: 1it [00:00,  1.26it/s]\nError getting embedding: Error code: 401 - {‘error’: {‘message’: ‘Your authentication token\nis not from a valid issuer.’, ‘type’: ‘invalid_request_error’, ‘param’: None, ‘code’: ‘invalid_issuer’}}\nEmbedding documents: 2it [00:01,  1.95it/s]\nError getting embedding: Error code: 401 - {‘error’: {‘message’: ‘Your authentication token\nis not from a valid issuer.’, ‘type’: ‘invalid_request_error’, ‘param’: None, ‘code’: ‘invalid_issuer’}}\nEmbedding documents: 3it [00:01,  2.08it/s]"
      },
      {
        "user_id": null,
        "content": "description: \"TDS Virtual TA Project Sample (but not the actual evaluation) Questions\"\n\nproviders:\n  - id: https\n    config:\n      url: YOUR_API_ENDPOINT # Replace this with your API endpoint\n      method: POST\n      headers:\n        Content-Type: application/json\n      body: |\n        {\n          \"question\": \"{{ question }}\"{% if image %},\n          \"image\": \"{{ image }}\"{% endif %}\n        }\n      transformResponse: json\n\n# Ensure JSON schema\ndefaultTest:\n  options:\n    provider:\n      id: https\n      config:\n        url: https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\n        method: POST\n        headers:\n          Content-Type: application/json\n          Authorization: Bearer YOUR_API_KEY  # Replace with your token\n        body: |\n          {\n            \"model\": \"gpt-4o-mini\",\n            \"messages\": [\n              {\"role\": \"system\", \"content\": \"You are an evaluator that checks if an output meets specific criteria. Analyze the output based on the given rubric and respond with a JSON object containing {\\\"reason\\\": \\\"your analysis\\\", \\\"score\\\": number between 0.0 and 1.0, \\\"pass\\\": true/false}.\"},\n              {\"role\": \"user\", \"content\": \"Output to evaluate: {{ output }}\\n\\nRubric: {{ rubric }}\"}\n            ],\n            \"temperature\": 0\n          }\n        transformResponse: json\n\n  assert:\n    - type: is-json\n      value:\n        type: object\n        required: [answer, links]\n        properties:\n          answer: { type: string }\n          links:\n            type: array\n            items:\n              type: object\n              required: [url, text]\n              properties:\n                url: { type: string }\n                text: { type: string }\n\ntests:\n  - vars:\n      question: The question asks to use gpt-3.5-turbo-0125 model but the ai-proxy provided by Anand sir only supports gpt-4o-mini. So should we just use gpt-4o-mini or use the OpenAI API for gpt3.5 turbo?\n      image: file://project-tds-virtual-ta-q1.webp\n      link: https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Clarifies use of gpt-3.5-turbo-0125 not gpt-4o-mini\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939\n\n  - vars:\n      question: If a student scores 10/10 on GA4 as well as a bonus, how would it appear on the dashboard?\n      link: https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-jan-2025/165959/388\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Mentions the dashboard showing \"110\"\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-jan-2025/165959\n  - vars:\n      question: I know Docker but have not used Podman before. Should I use Docker for this course?\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Recommends Podman for the course\n      - type: llm-rubric\n        transform: output.answer\n        value: Mentions that Docker is acceptable\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://tds.s-anand.net/#/docker\n  - vars:\n      question: When is the TDS Sep 2025 end-term exam?\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Says it doesn't know (since this information is not available yet)\n\nwriteLatestResults: true\n\ncommandLineOptions:\n  cache: true\nMake sure to replace “YOUR_API_KEY” with the API key that you have and “YOUR_API_ENDPOINT” with the URL and port you are running your API.\nNo need to keep the url and api_key in quotes, just paste them as it is."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/tds-p1-help-needed/179246/1",
    "posts": [
      {
        "user_id": null,
        "content": "I have uploaded exactly the files that need to be uploaded and I have set the required environment variables but I cannot get any output whatsoever. Setting the right API key, creating the correct database file- I have done all of it and yet I cannot figure out why\naren’t\nmy credits being used up (so API calling is\nnot working\n) or how to fix the error I keep getting repeatedly which is attached as follows. If anyone has completed, please help me out on this one. I have a friend who followed the exact same steps as given in a blueprint, and his one worked.\n@carlton\nsir pls help me out\nScreenshot 2025-06-14 232139\n1919×999 69.8 KB"
      },
      {
        "user_id": null,
        "content": "Can you share your yaml file also."
      },
      {
        "user_id": null,
        "content": "yeah sure- I am using the same one that was provided by S. Anand sir in the\nhttps://tds.s-anand.net/\nwebpage\nI have this one attached below\nproviders:\n  - id: https\n    config:\n      url: 'your app url'\n      method: POST\n      headers:\n        Content-Type: application/json\n      body: |\n        {\n          \"question\": \"{{ question }}\"{% if image %},\n          \"image\": \"{{ image }}\"{% endif %}\n        }\n \n        }\n      transformResponse: json\n\n# Ensure JSON schema\ndefaultTest:\n  options:\n    provider:\n      id: https\n      config:\n        url: https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\n        method: POST\n        headers:\n          Content-Type: application/json\n          Authorization: Bearer {{env.API_KEY}} # Replace with your token\n        body: |\n          {\n            \"model\": \"gpt-4o-mini\",\n            \"messages\": [\n              {\"role\": \"system\", \"content\": \"You are an evaluator that checks if an output meets specific criteria. Analyze the output based on the given rubric and respond with a JSON object containing {\\\"reason\\\": \\\"your analysis\\\", \\\"score\\\": number between 0.0 and 1.0, \\\"pass\\\": true/false}.\"},\n              {\"role\": \"user\", \"content\": \"Output to evaluate: {{ output }}\\n\\nRubric: {{ rubric }}\"}\n            ],\n            \"temperature\": 0\n          }\n        transformResponse: json\n\n  assert:\n    - type: is-json\n      value:\n        type: object\n        required: [answer, links]\n        properties:\n          answer: { type: string }\n          links:\n            type: array\n            items:\n              type: object\n              required: [url, text]\n              properties:\n                url: { type: string }\n                text: { type: string }\n\ntests:\n  - vars:\n      question: The question asks to use gpt-3.5-turbo-0125 model but the ai-proxy provided by Anand sir only supports gpt-4o-mini. So should we just use gpt-4o-mini or use the OpenAI API for gpt3.5 turbo?\n      image: file://project-tds-virtual-ta-q1.webp\n      link: https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Clarifies use of gpt-3.5-turbo-0125 not gpt-4o-mini\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939\n\n  - vars:\n      question: If a student scores 10/10 on GA4 as well as a bonus, how would it appear on the dashboard?\n      link: https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-jan-2025/165959/388\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Mentions the dashboard showing \"110\"\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-jan-2025/165959\n  - vars:\n      question: I know Docker but have not used Podman before. Should I use Docker for this course?\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Recommends Podman for the course\n      - type: llm-rubric\n        transform: output.answer\n        value: Mentions that Docker is acceptable\n      - type: contains\n        transform: JSON.stringify(output.links)\n        value: https://tds.s-anand.net/#/docker\n  - vars:\n      question: When is the TDS Sep 2025 end-term exam?\n    assert:\n      - type: llm-rubric\n        transform: output.answer\n        value: Says it doesn't know (since this information is not available yet)\n\nwriteLatestResults: true\n\ncommandLineOptions:\n  cache: false"
      },
      {
        "user_id": null,
        "content": "Have you modified this yanl file by changing the url to your api endpoint?"
      },
      {
        "user_id": null,
        "content": "yes absolutely, well an update is, I got 3 successes and just 1 failure instead of 0 successes and 4 failures. turns out I was missing the word query from the url endpoint so that’s why it was unable to fetch.\nthe problem I am stuck at right now is in the screenshot shown below\nScreenshot 2025-06-15 134631\n1919×851 57.3 KB"
      },
      {
        "user_id": null,
        "content": "This is related to your embeddings or your propmt i believe.. not avle to find relevant answer. May be try changing your prompt or check the topchunks it got for this request and find whether it is getting the correct chunka nd it has the required details."
      },
      {
        "user_id": null,
        "content": "okay, got it. I will try that and see. Thank you for your help, really appreciate it."
      },
      {
        "user_id": null,
        "content": "Brother can you please help ? Actually i am using render for api hosting when ever i run this yaml file with image link i got error as render can’t process image can you please sugest a way or any new api hosting platform and also on which software you running the yaml file (i acctually using ubuntu)"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/tds-references-guidelines/67216/1",
    "posts": [
      {
        "user_id": null,
        "content": "Course Portal\nPublic Course Portal Link\nInstructors\nPrasanna -\n@iamprasna\nCarlton -\n@carlton\nTags Usage\nPractice Question -\nWeek-num\nPractice-question\nGraded Question -\nWeek-num\nGraded-question\nOperational -\noperational\nExam -\nquiz\nProject -\nproject-num\nTerm -\ntermNum-YYYY\nCalendar\nCourse/subject calendar\nImportant Links\nGrading Document\nAnnouncement Group\nOfficial YouTube channel\nPurpose of ROE\nCourse Feedback\nHere’s students’ feedback:\nIt\nused\nto be an easy course until 2024.\n#\n#\n#\nNow it’s hard and covers more. Take it in your last semester if possible.\n#\n#\n#\nPlan extra time. It takes more time than typical 3-credit courses.\n#\n#\n#\nLLMs grade you – unpredictably.\n#\n#\nThe ROE is hard.\n#"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/unable-to-deploy-api-on-render/179292/1",
    "posts": [
      {
        "user_id": null,
        "content": "this is my render log\nERROR: Exception:\nJun 16 05:06:01 AM\nTraceback (most recent call last):\nJun 16 05:06:01 AM\nFile “/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/cli/base_command.py”, line 105, in _run_wrapper\nJun 16 05:06:01 AM\nstatus = _inner_run()\nJun 16 05:06:01 AM\nFile “/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/cli/base_command.py”, line 96, in _inner_run\nJun 16 05:06:01 AM\nreturn self.run(options, args)\nJun 16 05:06:01 AM\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/cli/req_command.py\", line 68, in wrapper\n\nJun 16 05:06:01 AM\n\nreturn func(self, options, args)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/commands/install.py\", line 387, in run\n\nJun 16 05:06:01 AM\n\nrequirement_set = resolver.resolve(\n\nJun 16 05:06:01 AM\n\nreqs, check_supported_wheels=not options.target_dir\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 96, in resolve\n\nJun 16 05:06:01 AM\n\nresult = self._result = resolver.resolve(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\ncollected.requirements, max_rounds=limit_how_complex_resolution_can_be\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 515, in resolve\n\nJun 16 05:06:01 AM\n\nstate = resolution.resolve(requirements, max_rounds=max_rounds)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 388, in resolve\n\nJun 16 05:06:01 AM\n\nself._add_to_criteria(self.state.criteria, r, parent=None)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 141, in _add_to_criteria\n\nJun 16 05:06:01 AM\n\nif not criterion.candidates:\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/structs.py\", line 194, in __bool__\n\nJun 16 05:06:01 AM\n\nreturn bool(self._sequence)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 163, in __bool__\n\nJun 16 05:06:01 AM\n\nself._bool = any(self)\n\nJun 16 05:06:01 AM\n\n~~~^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 147, in <genexpr>\n\nJun 16 05:06:01 AM\n\nreturn (c for c in iterator if id(c) not in self._incompatible_ids)\n\nJun 16 05:06:01 AM\n\n^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 37, in _iter_built\n\nJun 16 05:06:01 AM\n\ncandidate = func()\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 187, in _make_candidate_from_link\n\nJun 16 05:06:01 AM\n\nbase: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nlink, template, name, version\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 233, in _make_base_candidate_from_link\n\nJun 16 05:06:01 AM\n\nself._link_candidate_cache[link] = LinkCandidate(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nlink,\n\nJun 16 05:06:01 AM\n\n^^^^^\n\nJun 16 05:06:01 AM\n\n...<3 lines>...\n\nJun 16 05:06:01 AM\n\nversion=version,\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 306, in __init__\n\nJun 16 05:06:01 AM\n\nsuper().__init__(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nlink=link,\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n...<4 lines>...\n\nJun 16 05:06:01 AM\n\nversion=version,\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 159, in __init__\n\nJun 16 05:06:01 AM\n\nself.dist = self._prepare()\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 236, in _prepare\n\nJun 16 05:06:01 AM\n\ndist = self._prepare_distribution()\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 317, in _prepare_distribution\n\nJun 16 05:06:01 AM\n\nreturn preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 532, in prepare_linked_requirement\n\nJun 16 05:06:01 AM\n\nreturn self._prepare_linked_requirement(req, parallel_builds)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 647, in _prepare_linked_requirement\n\nJun 16 05:06:01 AM\n\ndist = _get_prepared_distribution(\n\nJun 16 05:06:01 AM\n\nreq,\n\nJun 16 05:06:01 AM\n\n...<3 lines>...\n\nJun 16 05:06:01 AM\n\nself.check_build_deps,\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 71, in _get_prepared_distribution\n\nJun 16 05:06:01 AM\n\nabstract_dist.prepare_distribution_metadata(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\nfinder, build_isolation, check_build_deps\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 56, in prepare_distribution_metadata\n\nJun 16 05:06:01 AM\n\nself._install_build_reqs(finder)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 126, in _install_build_reqs\n\nJun 16 05:06:01 AM\n\nbuild_reqs = self._get_build_requires_wheel()\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 103, in _get_build_requires_wheel\n\nJun 16 05:06:01 AM\n\nreturn backend.get_requires_for_build_wheel()\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_internal/utils/misc.py\", line 702, in get_requires_for_build_wheel\n\nJun 16 05:06:01 AM\n\nreturn super().get_requires_for_build_wheel(config_settings=cs)\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 196, in get_requires_for_build_wheel\n\nJun 16 05:06:01 AM\n\nreturn self._call_hook(\n\nJun 16 05:06:01 AM\n\n~~~~~~~~~~~~~~~^\n\nJun 16 05:06:01 AM\n\n\"get_requires_for_build_wheel\", {\"config_settings\": config_settings}\n\nJun 16 05:06:01 AM\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\n^\n\nJun 16 05:06:01 AM\n\nFile \"/opt/render/project/src/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 402, in _call_hook\n\nJun 16 05:06:01 AM\n\nraise BackendUnavailable(\n\nJun 16 05:06:01 AM\n\n...<4 lines>...\n\nJun 16 05:06:01 AM\n\n)\n\nJun 16 05:06:01 AM\n\npip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'\n\nJun 16 05:06:02 AM\n\n==> Build failed 😞\n\npls help me fix this sir. thank you."
      },
      {
        "user_id": null,
        "content": "(post deleted by author)"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/iitm-github-account-flagged/179311/2",
    "posts": [
      {
        "user_id": null,
        "content": "My IITM GitHub account is flagged and I am not able to deploy my TDS project 1 on third-party applications, kindly help me out with this, thank you\nScreenshot (1225)\n1920×1080 273 KB"
      },
      {
        "user_id": null,
        "content": "Shall I deploy the project using my personal Github account, please clarify this\n@s.anand\nSir and\n@carlton\nSir!!"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/image-size-issue-with-the-railway-app-deployment-made/179213/1",
    "posts": [
      {
        "user_id": null,
        "content": "I have tried to deploy the app to\nrailway.com\nbut getting the error like this\nimage\n1917×945 65.7 KB\nIssue witn the image build, but we don’t have any control over it..\nAny other deployment resources??"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/tds-project-1-2025/179103/1",
    "posts": [
      {
        "user_id": null,
        "content": "I’ve watched the YouTube sessions for Project 1, but I’m feeling quite confused. I’ve managed to scrape data from Discourse, and the content is now saved in multiple files. I’ve converted these files into\n.md\n(Markdown) format, but I’m having trouble handling the images — I’m not able to extract or display them properly.   Can anyone help?"
      },
      {
        "user_id": null,
        "content": "Can you please clarify how you scraped the data . I am not able to do it. Please Help me."
      },
      {
        "user_id": null,
        "content": "You can watch project sessions of tds in youtube playlist. They have mentioned and shown example of how to scrape the data."
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/npx-y-promptfoo-eval-config-project-tds-virtual-ta-promptfoo-yaml-error/179170",
    "posts": [
      {
        "user_id": null,
        "content": "npx -y promptfoo eval --config project-tds-virtual-ta-promptfoo.yaml\ni am getting the following error \n expected output to contain \"https://discourse.online...\ncould you pls tell what changes should i make to my api code. thanks\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom typing import Optional, List\nimport json\nfrom fastapi.responses import JSONResponse\n\n# Load data from JSON file\nwith open(\"discourse_posts.json\", \"r\") as f:\n    discourse_posts = json.load(f)\n\napp = FastAPI()\n\n# Define request/response models\nclass QuestionRequest(BaseModel):\n    question: str\n    image: Optional[str] = None\n\nclass Link(BaseModel):\n    url: str\n    text: str\n\nclass AnswerResponse(BaseModel):\n    answer: str\n    links: List[Link]\n    url: str\n    topic_title: str\n\n@app.post(\"/api\", response_model=AnswerResponse)\nasync def get_answer(request: QuestionRequest):\n    print(\"Received question:\", request.question)\n    question = request.question\n    for post in discourse_posts:\n        if any(word.lower() in question.lower() for word in post[\"question_keywords\"]):\n            return AnswerResponse(\n                answer=post[\"answer\"],\n                links=[Link(**link) for link in post[\"links\"]],\n                url=post[\"url\"],\n                topic_title=post[\"topic_title\"]\n            )\n\n    # Default fallback response with required fields\n    return AnswerResponse(\n        answer=\"Sorry, I couldn't find an answer to your question.\",\n        links=[],\n        url=\"https://tds.s-anand.net/#/\",\n        topic_title=\"Unknown topic\"\n    )\n\n@app.get(\"/\")\nasync def read_root():\n    return {\"message\": \"TDS API server is running.\"}\n\n@app.get(\"/favicon.ico\")\nasync def favicon():\n    return {}\n\n\npls help @jivraj @hrithik"
      },
      {
        "user_id": null,
        "content": "@Jivraj\n@HritikRoshan_HRM"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/guide-for-tds-project-1/178649/2",
    "posts": [
      {
        "user_id": null,
        "content": "Where can I get a reference or some material that may Guide me to complete the project."
      },
      {
        "user_id": null,
        "content": "github.com\nGitHub - 23f3004008/TDS-Project1-Data\nContribute to 23f3004008/TDS-Project1-Data development by creating an account on GitHub.\nThis is a good starting point for web scraping"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-may-2025/178881",
    "posts": [
      {
        "user_id": null,
        "content": "Please post any questions related to\nGraded Assignment 4 - Data Sourcing\n.\nDeadline:\nSunday, June 22, 2025 11:59 PM\n@carlton\n@Jivraj\n@HritikRoshan_HRM"
      },
      {
        "user_id": null,
        "content": "Subject:\nIssue with Scraping BBC Weather API for Nur-Sultan JSON Forecast\nQuestion 4: Scraping BBC Weather API for Nur-Sultan Weather Forecast\nI’m trying to retrieve the JSON weather forecast description for Nur-Sultan using the BBC Weather API. However, I noticed that the BBC website lists the city as “Astana” instead of Nur-Sultan. When I attempt to use the JSON data for Astana, I encounter the following error:\nTypeError: Cannot read properties of undefined (reading ‘id’)\nHow should I proceed to correctly scrape the weather forecast for Nur-Sultan?  how can I resolve the TypeError issue? Any guidance on handling city name"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/having-issue-while-submitting-the-project/179139",
    "posts": [
      {
        "user_id": null,
        "content": "Hello, i decided to deploy my virtual assistant project for TDS May 2025 term on Render.\nthe url is accepting GET requests for “/” endpoint and POST requests for “/api/” endpoint as instructed by Sirs. but it seems that the form where i’m supposed to provide github repo link and deployment public url, is sending an OPTIONS request to my Render deployed application, which it is dismissing by saying method not allowed. what to do??\nEDIT: enabling CORS let me send an OPTIONS request from the submission form so i was able to submit.\nlater i sent promptfoo as well as regular curls to Render url and they worked too. Although once it shut down, it just isn’t starting back up again; sending curls now gives me some really long html and doesn’t even send any api calls to the render url. what to do?\n@carlton\n@Jivraj"
      }
    ]
  },
  {
    "url": "https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939/6",
    "posts": [
      {
        "user_id": null,
        "content": "image\n756×295 19.5 KB\nThe question asks to use gpt-3.5-turbo-0125 model but the ai-proxy provided by Anand sir only supports gpt-4o-mini. So should we just use gpt-4o-mini or use the OpenAI API for gpt3.5 turbo?\n@carlton"
      },
      {
        "user_id": null,
        "content": "I tried gpt-3.5-turbo-0125 with python’s tiktoken library , I got a different value for prompt token compared gpt-4o-mini from the proxy api."
      },
      {
        "user_id": null,
        "content": "My understanding is that you just have to use a tokenizer, similar to what Prof. Anand used, to get the number of tokens and multiply that by the given rate."
      },
      {
        "user_id": null,
        "content": "Use the model that’s mentioned in the question."
      },
      {
        "user_id": null,
        "content": "The answer should be 0.00165 right."
      }
    ]
  }
]